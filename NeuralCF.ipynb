{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "weight_decay = 1e-5\n",
    "num_classes = 2\n",
    "lr = 2e-2\n",
    "negative_sum = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guoyuhao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId movieId  label\n",
      "0       1    1873      0\n",
      "1       1    3081      0\n",
      "2       1    2643      0\n",
      "3       1     332      0\n",
      "4       1    2971      0\n",
      "   userId  movieId  label\n",
      "0       1     1193      1\n",
      "1       1      661      1\n",
      "2       1      914      1\n",
      "3       1     3408      1\n",
      "4       1     2355      1\n",
      "(1876977, 2) (331232, 2) (1876977,) (331232,)\n",
      "        userId  movieId\n",
      "605734    3029     1628\n",
      "290934    1455     2145\n",
      "540295    2702     2678\n",
      "329972    1947     1103\n",
      "147465     949     1580\n",
      "605734    0\n",
      "290934    0\n",
      "540295    0\n",
      "329972    1\n",
      "147465    1\n",
      "Name: label, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./ratings.dat', sep='::', names=['userId', 'movieId', 'rating', 'time'], usecols=[0,1])\n",
    "dataList = data.groupby(by='userId').agg({'movieId':list})\n",
    "dataList['userId'] = dataList.index\n",
    "dataList.reset_index(drop=True)\n",
    "movieIds = data.movieId.unique()\n",
    "\n",
    "#负采样\n",
    "negative = dict()\n",
    "for userId in dataList['userId']:\n",
    "    negatives = list()\n",
    "    while len(negatives) < negative_sum:\n",
    "        movieId = random.randint(1, 3952)\n",
    "        if movieId not in dataList.loc[userId].movieId:\n",
    "            negatives.append(movieId)\n",
    "    negative[userId] = negatives\n",
    "\n",
    "negative = pd.DataFrame.from_dict(negative, orient='index')\n",
    "negative['userId'] = negative.index\n",
    "negative['movieId'] = negative.apply(lambda x:[x[i] for i in range(negative_sum)], axis=1)\n",
    "negative = negative[['userId', 'movieId']]\n",
    "negative = negative.explode('movieId').reset_index(drop=True)\n",
    "negative['label'] = 0\n",
    "print(negative.head())\n",
    "\n",
    "data = data.explode('movieId').reset_index(drop=True)\n",
    "data['label'] = 1\n",
    "print(data.head())\n",
    "\n",
    "#测试集和训练集划分\n",
    "data = pd.concat([data, negative]).astype(np.int32)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.iloc[:, 0:2], data.iloc[:, 2], test_size=0.15, random_state=2022)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3952\n"
     ]
    }
   ],
   "source": [
    "user_num = data.userId.nunique()\n",
    "movie_num = data.movieId.nunique()\n",
    "print(user_num, movie_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2])\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MovieDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "train_dataset = MovieDataset(torch.tensor(x_train.values), torch.tensor(y_train.values))\n",
    "test_dataset = MovieDataset(torch.tensor(x_test.values), torch.tensor(y_test.values))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "iter_x, iter_y = next(iter(train_loader))\n",
    "print(iter_x.shape)\n",
    "print(iter_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCF(nn.Module):\n",
    "    def __init__(self, userIds, movieIds, mlp_hidden_units, gmf_embedding_num, mlp_embedding_num, dropout):\n",
    "        super(NeuralCF, self).__init__()\n",
    "        self.userIds = userIds\n",
    "        self.movieIds = movieIds\n",
    "        self.mlp_hidden_units = mlp_hidden_units\n",
    "        self.gmf_embedding_num = gmf_embedding_num\n",
    "        self.mlp_embedding_num = mlp_embedding_num\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        #gmf的embedding层\n",
    "        self.gmf_user_embedding = nn.Embedding(userIds, gmf_embedding_num)\n",
    "        self.gmf_movie_embedding = nn.Embedding(movieIds, gmf_embedding_num)\n",
    "        \n",
    "        #mlp的embedding层\n",
    "        self.mlp_user_embedding = nn.Embedding(userIds, mlp_embedding_num)\n",
    "        self.mlp_movie_embedding = nn.Embedding(movieIds, mlp_embedding_num)\n",
    "        \n",
    "        #mlp的多层全连接层\n",
    "        mlp_layers = []\n",
    "        input_size = 2 * self.mlp_embedding_num\n",
    "        mlp_layers.append(nn.Linear(input_size, hidden_units[0]))\n",
    "        mlp_layers.append(nn.Dropout(self.dropout))\n",
    "        mlp_layers.append(nn.ReLU())\n",
    "        for i in range(1, len(hidden_units)):\n",
    "            input_units = hidden_units[i - 1]\n",
    "            output_units = hidden_units[i]\n",
    "            mlp_layers.append(nn.Linear(input_units, output_units))\n",
    "            mlp_layers.append(nn.Dropout(self.dropout))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "        self.mlp_layers = nn.Sequential(*mlp_layers)\n",
    "        \n",
    "        output_layer_input_units = self.gmf_embedding_num + self.mlp_hidden_units[-1]\n",
    "        self.output_layer = nn.Linear(output_layer_input_units, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        users = x[:,0].long()\n",
    "        movies = x[:,1].long()\n",
    "        \n",
    "        user_gmf_embedding = self.gmf_user_embedding(users)\n",
    "        movie_gmf_embedding = self.gmf_movie_embedding(movies)\n",
    "        \n",
    "        user_mlp_embedding = self.mlp_user_embedding(users)\n",
    "        movie_mlp_embedding = self.mlp_movie_embedding(movies)\n",
    "        \n",
    "        #gmf执行element-wise product操作\n",
    "        gmf_output = user_gmf_embedding * movie_gmf_embedding\n",
    "        \n",
    "        #mlp块通过堆叠的全连接层+激活函数\n",
    "        mlp_input = torch.cat([user_mlp_embedding, movie_mlp_embedding], dim=-1)\n",
    "        mlp_output = self.mlp_layers(mlp_input)\n",
    "        \n",
    "        #将gmf和mlp的输出结果concat起来，送入最后的全连接层预测结果，并使用sigmoid函数将输出结果映射到0-1之间\n",
    "        output = self.output_layer(torch.cat([gmf_output, mlp_output], dim=-1))\n",
    "        output = self.sigmoid(output).squeeze()\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralCF(\n",
       "  (gmf_user_embedding): Embedding(6040, 2)\n",
       "  (gmf_movie_embedding): Embedding(3952, 2)\n",
       "  (mlp_user_embedding): Embedding(6040, 16)\n",
       "  (mlp_movie_embedding): Embedding(3952, 16)\n",
       "  (mlp_layers): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=8, bias=True)\n",
       "    (1): Dropout(p=0.0, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=8, out_features=2, bias=True)\n",
       "    (4): Dropout(p=0.0, inplace=False)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (output_layer): Linear(in_features=4, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [8, 2]\n",
    "gmf_embedding_num = 2\n",
    "mlp_embedding_num = 16\n",
    "dropout = 0.\n",
    "net = NeuralCF(user_num, movie_num, hidden_units, gmf_embedding_num, mlp_embedding_num, dropout)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    #训练模型并输出测试集每一轮的loss\n",
    "    criterion = nn.BCELoss()\n",
    "    for t, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        total = net.forward(batch_x)\n",
    "        loss = criterion(total, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(net.state_dict())\n",
    "\n",
    "        \n",
    "    r = test()\n",
    "    print('Epoch %d, loss=%.4f' % (epoch, r))\n",
    "def test():\n",
    "    #测试集测试\n",
    "    criterion = nn.BCELoss()\n",
    "    all_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for t, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            pred = net.forward(batch_x)\n",
    "            gt_label = batch_y.cpu().data.numpy()\n",
    "            pred_proba = pred.cpu().data.numpy()\n",
    "            gt_labels.append(gt_label)\n",
    "            pred_labels.append(pred_proba)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            all_loss += loss.item()\n",
    "            i += 1\n",
    "        gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "        pred_labels = pred_labels.reshape(-1)\n",
    "        auc = roc_auc_score(gt_labels, pred_labels)\n",
    "        print('auc:', auc, 'gt_labels:', gt_labels.shape, 'pred_labels:', pred_labels.shape)\n",
    "    return all_loss / i\n",
    "def predict(x):\n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.float().to(device)\n",
    "        out1 = net.forward(x)\n",
    "        out = out1.cpu().data.numpy()\n",
    "        out[out>=0.5] = 1.0\n",
    "        out[out<0.5] = 0.0\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.5005493144428145 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 0, loss=0.7004\n",
      "auc: 0.49961504681403346 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 1, loss=0.7004\n",
      "auc: 0.5008445569355171 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 2, loss=0.7000\n",
      "auc: 0.8890800000683443 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 3, loss=0.4307\n",
      "auc: 0.9051854890691389 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 4, loss=0.3934\n",
      "auc: 0.9082788126662582 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 5, loss=0.3861\n",
      "auc: 0.9091886227642041 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 6, loss=0.3844\n",
      "auc: 0.9097349545449724 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 7, loss=0.3815\n",
      "auc: 0.9100320470032056 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 8, loss=0.3819\n",
      "auc: 0.9086712755668553 gt_labels: (331232,) pred_labels: (331232,)\n",
      "Epoch 9, loss=0.3871\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay=0)\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.826810211573761\n"
     ]
    }
   ],
   "source": [
    "#训练好的模型预测测试集\n",
    "test_x = x_test.values\n",
    "test_pred = predict(test_x)\n",
    "test_label = y_test.values\n",
    "acc = accuracy_score(test_pred, test_label)\n",
    "print('accuracy:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
