{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 13105) (1599,) (400, 13105) (400,)\n",
      "            I1        I2        I3        I4        I5        I6        I7  \\\n",
      "64    0.010526  0.000381  0.000591  0.091954  0.000007  0.001725  0.000603   \n",
      "917   0.000000  0.000381  0.000236  0.057471  0.004469  0.013583  0.016888   \n",
      "290   0.000000  0.004704  0.000000  0.103448  0.039948  0.000000  0.000000   \n",
      "1198  0.063158  0.000254  0.001774  0.045977  0.000000  0.000647  0.003619   \n",
      "1991  0.000000  0.000254  0.000236  0.011494  0.015662  0.018111  0.000603   \n",
      "\n",
      "            I8        I9   I10  ...  C26_fbe10aa8  C26_fcd456fa  C26_fcd5a3f4  \\\n",
      "64    0.014625  0.001419  0.25  ...             0             0             0   \n",
      "917   0.034735  0.008338  0.00  ...             0             0             0   \n",
      "290   0.074954  0.001774  0.00  ...             0             0             0   \n",
      "1198  0.010969  0.000710  0.25  ...             0             0             0   \n",
      "1991  0.001828  0.024304  0.00  ...             0             0             0   \n",
      "\n",
      "      C26_fd6ccd1e  C26_fdd86175  C26_fe7d4d4a  C26_ff2cdc2b  C26_ff86d5e0  \\\n",
      "64               0             0             0             0             0   \n",
      "917              0             0             0             0             0   \n",
      "290              0             0             0             0             0   \n",
      "1198             0             0             0             0             0   \n",
      "1991             0             0             0             0             0   \n",
      "\n",
      "      C26_ffc123e9  label  \n",
      "64               0    0.0  \n",
      "917              0    0.0  \n",
      "290              0    0.0  \n",
      "1198             0    0.0  \n",
      "1991             0    0.0  \n",
      "\n",
      "[5 rows x 13105 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guoyuhao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/guoyuhao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.txt')\n",
    "columns = data.columns.tolist()\n",
    "categorical_features = [col for col in columns if 'C' in col]\n",
    "numeric_features = [col for col in columns if col not in categorical_features]\n",
    "numeric_features.remove('label')\n",
    "data[categorical_features] = data[categorical_features].fillna('-1')\n",
    "data[numeric_features] = data[numeric_features].fillna(0)\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_features)\n",
    "scaler = MinMaxScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n",
    "\n",
    "data_X = data.drop('label', axis=1)\n",
    "data_y = data['label'].astype(np.float64)\n",
    "\n",
    "trains, tests, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2)\n",
    "trains['label'] = y_train\n",
    "tests['label'] = y_test\n",
    "print(trains.shape, y_train.shape, tests.shape, y_test.shape)\n",
    "print(trains.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "torch.Size([10, 13104])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 10\n",
    "num_workers = 4\n",
    "lr = 1e-4\n",
    "epochs = 20\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        cols = df.columns.tolist()\n",
    "        cols.remove('label')\n",
    "        self.X = df.loc[:, cols].values\n",
    "        self.y = df.loc[:, 'label'].values\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        data_x = self.X[idx]\n",
    "        data_y = self.y[idx]\n",
    "        return data_x, data_y\n",
    "\n",
    "train_data = MyDataset(trains)\n",
    "test_data = MyDataset(tests)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "iter_x, iter_y = next(iter(train_loader))\n",
    "print(iter_y)\n",
    "print(iter_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSPLM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSPLM(nn.Module):\n",
    "    def __init__(self, feature_num, m):\n",
    "        super(LSPLM, self).__init__()\n",
    "        self.m = m\n",
    "        self.feature_num = feature_num\n",
    "        self.softmax = nn.Sequential(nn.Linear(self.feature_num, self.m).double(),\n",
    "                                    nn.Softmax(dim=1).double())\n",
    "        self.logistic = nn.Sequential(nn.Linear(self.feature_num, self.m).double(),\n",
    "                                     nn.Sigmoid())        \n",
    "    def forward(self, x):\n",
    "        logistic_out = self.logistic(x)\n",
    "        softmax_out = self.softmax(x)\n",
    "        combine_out = logistic_out.mul(softmax_out)\n",
    "        return combine_out.sum(1)\n",
    "    def fit(self, data, optimizer, epochs=100):\n",
    "        #训练模型并输出测试集每一轮的loss\n",
    "        criterion = nn.BCELoss(reduction='mean')\n",
    "        for epoch in range(epochs):\n",
    "            for t, (batch_x, batch_y) in enumerate(data):\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                total = self.forward(batch_x)\n",
    "                loss = criterion(total, batch_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loader_test = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "            r = self.test(loader_test)\n",
    "            print('Epoch %d, loss=%.4f' % (epoch, r))\n",
    "    def test(self, data):\n",
    "        #测试集测试\n",
    "        criterion = nn.BCELoss(reduction='mean')\n",
    "        all_loss = 0\n",
    "        gt_labels = []\n",
    "        pred_labels = []\n",
    "        i = 0\n",
    "        with torch.no_grad():\n",
    "            for t, (batch_x, batch_y) in enumerate(data):\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                pred = self.forward(batch_x)\n",
    "                gt_label = batch_y.cpu().data.numpy()\n",
    "                pred_proba = pred.cpu().data.numpy()\n",
    "                gt_labels.append(gt_label)\n",
    "                pred_labels.append(pred_proba)\n",
    "                loss = criterion(pred, batch_y)\n",
    "                all_loss += loss.item()\n",
    "                i += 1\n",
    "        gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "        pred_labels = pred_labels.reshape(len(pred_labels),)\n",
    "        auc = roc_auc_score(gt_labels, pred_labels)\n",
    "        print('auc:', auc, 'gt_lables:', gt_labels.shape, 'pred_labels:', pred_labels.shape)\n",
    "        return all_loss / i\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            #预测出X的标签\n",
    "            x = torch.from_numpy(x)\n",
    "            x = x.to(device)\n",
    "            out1 = self.forward(x)\n",
    "            out = out1.cpu().data.numpy()\n",
    "            out[out >= 0.5] = 1.0\n",
    "            out[out<0.5] = 0.0\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.625 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 0, loss=0.6454\n",
      "auc: 0.627039627039627 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 1, loss=0.6093\n",
      "auc: 0.6263111888111889 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 2, loss=0.5815\n",
      "auc: 0.6255099067599067 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 3, loss=0.5592\n",
      "auc: 0.6285693473193473 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 4, loss=0.5410\n",
      "auc: 0.6313738344988343 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 5, loss=0.5283\n",
      "auc: 0.634833916083916 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 6, loss=0.5201\n",
      "auc: 0.6400786713286714 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 7, loss=0.5148\n",
      "auc: 0.6432837995337995 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 8, loss=0.5112\n",
      "auc: 0.6487470862470863 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 9, loss=0.5085\n",
      "auc: 0.6532634032634033 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 10, loss=0.5064\n",
      "auc: 0.6579254079254079 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 11, loss=0.5046\n",
      "auc: 0.6617497086247086 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 12, loss=0.5028\n",
      "auc: 0.6655011655011654 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 13, loss=0.5011\n",
      "auc: 0.6705638111888111 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 14, loss=0.4996\n",
      "auc: 0.6746794871794872 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 15, loss=0.4980\n",
      "auc: 0.6785037878787878 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 16, loss=0.4966\n",
      "auc: 0.6804341491841492 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 17, loss=0.4952\n",
      "auc: 0.680871212121212 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 18, loss=0.4940\n",
      "auc: 0.682145979020979 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 19, loss=0.4929\n",
      "auc: 0.6830929487179488 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 20, loss=0.4919\n",
      "auc: 0.6838578088578088 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 21, loss=0.4912\n",
      "auc: 0.684586247086247 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 22, loss=0.4904\n",
      "auc: 0.684149184149184 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 23, loss=0.4898\n",
      "auc: 0.684586247086247 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 24, loss=0.4895\n",
      "auc: 0.6841127622377623 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 25, loss=0.4891\n",
      "auc: 0.6835664335664335 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 26, loss=0.4888\n",
      "auc: 0.6840399184149185 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 27, loss=0.4886\n",
      "auc: 0.6842220279720279 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 28, loss=0.4882\n",
      "auc: 0.6840399184149184 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 29, loss=0.4882\n"
     ]
    }
   ],
   "source": [
    "m = 4\n",
    "feature_num = data_X.shape[1]\n",
    "ls_plm = LSPLM(feature_num, m)\n",
    "ls_plm.to(device)\n",
    "optimizer = optim.Adam(ls_plm.parameters(), lr=lr, weight_decay=0.0)\n",
    "ls_plm.fit(train_loader, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.6840399184149184 gt_lables: (400,) pred_labels: (400,)\n",
      "accuracy: 0.7775\n"
     ]
    }
   ],
   "source": [
    "#训练好的模型预测测试集\n",
    "ls_plm.test(test_loader)\n",
    "test_x = tests.drop('label', axis=1).values\n",
    "test_pred = ls_plm.predict(test_x)\n",
    "test_label = tests['label'].values\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_pred, test_label)\n",
    "print('accuracy:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
