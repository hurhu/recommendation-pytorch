{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "infinity = float(-2 ** 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python实现POLY2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_train(X, b, W, W_join):\n",
    "    #训练阶段 用当前的权重预测样本X的每个样本的概率\n",
    "    #一阶部分\n",
    "    sum_linear = b + X.dot(W)\n",
    "    samples = len(X)\n",
    "    features = len(X[0])\n",
    "    #二阶特征组合\n",
    "    X_join = []\n",
    "    for sample_index in range(samples):\n",
    "        sample = X[sample_index]\n",
    "        sample_join = []\n",
    "        for fea_j1_index in range(features):\n",
    "            for fea_j2_index in range(fea_j1_index + 1, features):\n",
    "                sample_join.append(sample[fea_j1_index] * sample[fea_j2_index])\n",
    "        X_join.append(sample_join)\n",
    "    X_join = np.array(X_join)\n",
    "    #二阶部分z值\n",
    "    sum_join = X_join.dot(W_join)\n",
    "    params = -(sum_linear + sum_join)\n",
    "    r = np.zeros(params.shape[0]) #生成维度为样本数的一维数组\n",
    "    for i in range(len(r)):\n",
    "        r[i] = 1 / (1 + math.exp(params[i]))\n",
    "    return r\n",
    "def sigmoid_predict(X, b, W, W_join):\n",
    "    #预测阶段 用当前W预测X的每个样本的标签，概率值大于等于0.5标签为1 否则标签为0\n",
    "    sum_linear = b + X.dot(W)\n",
    "    samples = len(X)\n",
    "    features = len(X[0])\n",
    "    #二阶特征组合\n",
    "    X_join = []\n",
    "    for sample_index in range(samples):\n",
    "        sample = X[sample_index]\n",
    "        sample_join = []\n",
    "        for fea_j1_index in range(features):\n",
    "            for fea_j2_index in range(fea_j1_index + 1, features):\n",
    "                sample_join.append(sample[fea_j1_index] * sample[fea_j2_index])\n",
    "        X_join.append(sample_join)\n",
    "    X_join = np.array(X_join)\n",
    "    #二阶部分z值\n",
    "    sum_join = X_join.dot(W_join)\n",
    "    params = -(sum_linear + sum_join)\n",
    "    r = np.zeros(params.shape[0])\n",
    "    for i in range(len(r)):\n",
    "        r[i] = 1 / (1 + math.exp(params[i]))\n",
    "        if r[i] >= 0.5:\n",
    "            r[i] = 1\n",
    "        else:\n",
    "            r[i] = 0\n",
    "    return r\n",
    "def sigmoid(Xi, b, W, W_join):\n",
    "    #计算某个样本在权重W下的概率\n",
    "    #一阶部分值\n",
    "    sum_linear = b + np.sum(Xi * W)\n",
    "    #二阶特征组合\n",
    "    features = len(Xi)\n",
    "    X_join = []\n",
    "    for fea_j1_index in range(features):\n",
    "        for fea_j2_index in range(fea_j1_index + 1, features):\n",
    "            X_join.append(Xi[fea_j1_index] * Xi[fea_j2_index])\n",
    "    X_join = np.array(X_join)\n",
    "    #二阶部分值\n",
    "    sum_join = np.sum(X_join * W_join)\n",
    "    params = -(sum_linear + sum_join)\n",
    "    r = 1 / (1 + math.exp(params))\n",
    "    return r\n",
    "\n",
    "class POLY2(object):\n",
    "    W = None\n",
    "    b = 0\n",
    "    W_join = None\n",
    "    m = 0\n",
    "    #训练\n",
    "    #alpha：学习率,accuracy时训练停止条件\n",
    "    def fit(self, X, y, alpha=0.01, accuracy=0.0001):\n",
    "        #插入第一列为1(即偏置项b)，构成Xb矩阵\n",
    "        self.W = np.full(X.shape[1], 0.5)#用0.5初始化一阶特征的权重向量W\n",
    "        self.m = X.shape[0] #样本数量\n",
    "        self.b = 1 #生成一列偏置项\n",
    "        dimension = X.shape[1] #输入数据的特征个数\n",
    "        self.W_join = np.full(dimension * (dimension - 1) // 2, 0.2)#用0.2初始化二阶组合特征的权重向量W_join\n",
    "        #梯度下降迭代\n",
    "        count = 1\n",
    "        while True:\n",
    "            oldJ = self.costFunc(X, y)\n",
    "            #根据上面的公式更新偏置项，一阶权重，二阶组合权重\n",
    "            error = sigmoid_train(X, self.b, self.W, self.W_join) - y\n",
    "            self.b -= alpha * np.sum(error) / self.m\n",
    "            for j in range(dimension):\n",
    "                self.W[j] -= alpha * np.sum(error * X[:,j]) / self.m\n",
    "            k = 0\n",
    "            for j1 in range(dimension):\n",
    "                for j2 in range(j1 + 1, dimension):\n",
    "                    self.W_join[k] -= alpha * np.sum(error * X[:,j1] * X[:,j2]) / self.m\n",
    "                    k += 1\n",
    "            newJ = self.costFunc(X, y)\n",
    "            if newJ == oldJ or math.fabs(newJ - oldJ) < accuracy:\n",
    "                print('代价函数迭代到最小值，退出!')\n",
    "                print('收敛到:', newJ)\n",
    "                break\n",
    "            print('迭代第', count, '次')\n",
    "            print('代价函数上一次的差:', (oldJ - newJ))\n",
    "            count += 1\n",
    "            \n",
    "    ##计算损失函数\n",
    "    def costFunc(self, X, y):\n",
    "        sums = 0.0\n",
    "        for i in range(self.m):\n",
    "            yPre = sigmoid(X[i,:], self.b, self.W, self.W_join)\n",
    "            if yPre == 1 or yPre == 0:\n",
    "                return infinity\n",
    "            sums += y[i] * math.log(yPre) + (1 - y[i]) * math.log(1 - yPre)\n",
    "        return -1 * sums / self.m\n",
    "    #预测\n",
    "    def predict(self, X):\n",
    "        return sigmoid_predict(X, self.b, self.W, self.W_join)\n",
    "    #用准确率衡量预测结果的好坏\n",
    "    def score(self, X_test, y_test):\n",
    "        y_predict = self.predict(X_test)\n",
    "        re = (y_test==y_predict)\n",
    "        re1 = Counter(re)\n",
    "        acc = re1[True] / (re1[True] + re1[False])\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代第 1 次\n",
      "代价函数上一次的差: 0.8094566333466062\n",
      "迭代第 2 次\n",
      "代价函数上一次的差: 0.8093638538877777\n",
      "迭代第 3 次\n",
      "代价函数上一次的差: 0.8088782984930427\n",
      "迭代第 4 次\n",
      "代价函数上一次的差: 0.8061375254411893\n",
      "迭代第 5 次\n",
      "代价函数上一次的差: 0.7896386684761383\n",
      "迭代第 6 次\n",
      "代价函数上一次的差: 0.6976315245236709\n",
      "迭代第 7 次\n",
      "代价函数上一次的差: 0.41553711924151787\n",
      "迭代第 8 次\n",
      "代价函数上一次的差: 0.13915077280168106\n",
      "迭代第 9 次\n",
      "代价函数上一次的差: 0.04052315016222954\n",
      "迭代第 10 次\n",
      "代价函数上一次的差: 0.014206442270451314\n",
      "迭代第 11 次\n",
      "代价函数上一次的差: 0.00831075886721977\n",
      "迭代第 12 次\n",
      "代价函数上一次的差: 0.006851980883903541\n",
      "迭代第 13 次\n",
      "代价函数上一次的差: 0.006129395371694296\n",
      "迭代第 14 次\n",
      "代价函数上一次的差: 0.005569343532794549\n",
      "迭代第 15 次\n",
      "代价函数上一次的差: 0.005088931204833114\n",
      "迭代第 16 次\n",
      "代价函数上一次的差: 0.004668377995375561\n",
      "迭代第 17 次\n",
      "代价函数上一次的差: 0.004297473433751031\n",
      "迭代第 18 次\n",
      "代价函数上一次的差: 0.003968669213687631\n",
      "迭代第 19 次\n",
      "代价函数上一次的差: 0.003675876666944855\n",
      "迭代第 20 次\n",
      "代价函数上一次的差: 0.0034140739188478486\n",
      "迭代第 21 次\n",
      "代价函数上一次的差: 0.003179079314096417\n",
      "迭代第 22 次\n",
      "代价函数上一次的差: 0.002967387458556278\n",
      "迭代第 23 次\n",
      "代价函数上一次的差: 0.0027760427623082923\n",
      "迭代第 24 次\n",
      "代价函数上一次的差: 0.0026025398580026005\n",
      "迭代第 25 次\n",
      "代价函数上一次的差: 0.0024447443618396125\n",
      "迭代第 26 次\n",
      "代价函数上一次的差: 0.0023008293414032432\n",
      "迭代第 27 次\n",
      "代价函数上一次的差: 0.002169224040800749\n",
      "迭代第 28 次\n",
      "代价函数上一次的差: 0.002048572246954261\n",
      "迭代第 29 次\n",
      "代价函数上一次的差: 0.001937698291370693\n",
      "迭代第 30 次\n",
      "代价函数上一次的差: 0.0018355791371830743\n",
      "迭代第 31 次\n",
      "代价函数上一次的差: 0.0017413213447850934\n",
      "迭代第 32 次\n",
      "代价函数上一次的差: 0.0016541419706777166\n",
      "迭代第 33 次\n",
      "代价函数上一次的差: 0.0015733526543085935\n",
      "迭代第 34 次\n",
      "代价函数上一次的差: 0.0014983463020770554\n",
      "迭代第 35 次\n",
      "代价函数上一次的差: 0.0014285858974741605\n",
      "迭代第 36 次\n",
      "代价函数上一次的差: 0.0013635950598657604\n",
      "迭代第 37 次\n",
      "代价函数上一次的差: 0.0013029500478483336\n",
      "迭代第 38 次\n",
      "代价函数上一次的差: 0.0012462729610774603\n",
      "迭代第 39 次\n",
      "代价函数上一次的差: 0.0011932259404517295\n",
      "迭代第 40 次\n",
      "代价函数上一次的差: 0.0011435062032136636\n",
      "迭代第 41 次\n",
      "代价函数上一次的差: 0.0010968417789064544\n",
      "迭代第 42 次\n",
      "代价函数上一次的差: 0.0010529878357800268\n",
      "迭代第 43 次\n",
      "代价函数上一次的差: 0.0010117235063552277\n",
      "迭代第 44 次\n",
      "代价函数上一次的差: 0.0009728491363814457\n",
      "迭代第 45 次\n",
      "代价函数上一次的差: 0.0009361838940731282\n",
      "迭代第 46 次\n",
      "代价函数上一次的差: 0.0009015636868706309\n",
      "迭代第 47 次\n",
      "代价函数上一次的差: 0.0008688393414749765\n",
      "迭代第 48 次\n",
      "代价函数上一次的差: 0.0008378750099225646\n",
      "迭代第 49 次\n",
      "代价函数上一次的差: 0.0008085467702700563\n",
      "迭代第 50 次\n",
      "代价函数上一次的差: 0.0007807413952765491\n",
      "迭代第 51 次\n",
      "代价函数上一次的差: 0.0007543552664857969\n",
      "迭代第 52 次\n",
      "代价函数上一次的差: 0.0007292934144646351\n",
      "迭代第 53 次\n",
      "代价函数上一次的差: 0.0007054686687641698\n",
      "迭代第 54 次\n",
      "代价函数上一次的差: 0.0006828009035358892\n",
      "迭代第 55 次\n",
      "代价函数上一次的差: 0.0006612163667236715\n",
      "迭代第 56 次\n",
      "代价函数上一次的差: 0.0006406470824424568\n",
      "迭代第 57 次\n",
      "代价函数上一次的差: 0.0006210303175768622\n",
      "迭代第 58 次\n",
      "代价函数上一次的差: 0.0006023081048513595\n",
      "迭代第 59 次\n",
      "代价函数上一次的差: 0.0005844268156551952\n",
      "迭代第 60 次\n",
      "代价函数上一次的差: 0.0005673367767897314\n",
      "迭代第 61 次\n",
      "代价函数上一次的差: 0.000550991926061839\n",
      "迭代第 62 次\n",
      "代价函数上一次的差: 0.0005353495022981034\n",
      "迭代第 63 次\n",
      "代价函数上一次的差: 0.0005203697659089748\n",
      "迭代第 64 次\n",
      "代价函数上一次的差: 0.0005060157466182172\n",
      "迭代第 65 次\n",
      "代价函数上一次的差: 0.0004922530153852606\n",
      "迭代第 66 次\n",
      "代价函数上一次的差: 0.0004790494779096238\n",
      "迭代第 67 次\n",
      "代价函数上一次的差: 0.00046637518741912687\n",
      "迭代第 68 次\n",
      "代价函数上一次的差: 0.0004542021747133418\n",
      "迭代第 69 次\n",
      "代价函数上一次的差: 0.00044250429367204136\n",
      "迭代第 70 次\n",
      "代价函数上一次的差: 0.00043125708064341295\n",
      "迭代第 71 次\n",
      "代价函数上一次的差: 0.0004204376263067522\n",
      "迭代第 72 次\n",
      "代价函数上一次的差: 0.0004100244587632376\n",
      "迭代第 73 次\n",
      "代价函数上一次的差: 0.0003999974367450143\n",
      "迭代第 74 次\n",
      "代价函数上一次的差: 0.00039033765195638226\n",
      "迭代第 75 次\n",
      "代价函数上一次的差: 0.00038102733966577373\n",
      "迭代第 76 次\n",
      "代价函数上一次的差: 0.00037204979676279393\n",
      "迭代第 77 次\n",
      "代价函数上一次的差: 0.00036338930657735247\n",
      "迭代第 78 次\n",
      "代价函数上一次的差: 0.00035503106983108407\n",
      "迭代第 79 次\n",
      "代价函数上一次的差: 0.00034696114115693316\n",
      "迭代第 80 次\n",
      "代价函数上一次的差: 0.0003391663706801343\n",
      "迭代第 81 次\n",
      "代价函数上一次的差: 0.0003316343502050012\n",
      "迭代第 82 次\n",
      "代价函数上一次的差: 0.00032435336359755776\n",
      "迭代第 83 次\n",
      "代价函数上一次的差: 0.00031731234099514893\n",
      "迭代第 84 次\n",
      "代价函数上一次的差: 0.00031050081650882064\n",
      "迭代第 85 次\n",
      "代价函数上一次的差: 0.000303908889118229\n",
      "迭代第 86 次\n",
      "代价函数上一次的差: 0.000297527186486856\n",
      "迭代第 87 次\n",
      "代价函数上一次的差: 0.0002913468314511766\n",
      "迭代第 88 次\n",
      "代价函数上一次的差: 0.00028535941095973044\n",
      "迭代第 89 次\n",
      "代价函数上一次的差: 0.00027955694726102334\n",
      "迭代第 90 次\n",
      "代价函数上一次的差: 0.00027393187115533\n",
      "迭代第 91 次\n",
      "代价函数上一次的差: 0.0002684769971433229\n",
      "迭代第 92 次\n",
      "代价函数上一次的差: 0.0002631855003200727\n",
      "迭代第 93 次\n",
      "代价函数上一次的差: 0.00025805089487486096\n",
      "迭代第 94 次\n",
      "代价函数上一次的差: 0.0002530670140717915\n",
      "迭代第 95 次\n",
      "代价函数上一次的差: 0.00024822799159466766\n",
      "迭代第 96 次\n",
      "代价函数上一次的差: 0.00024352824415188254\n",
      "迭代第 97 次\n",
      "代价函数上一次的差: 0.0002389624552446845\n",
      "迭代第 98 次\n",
      "代价函数上一次的差: 0.00023452556001054073\n",
      "迭代第 99 次\n",
      "代价函数上一次的差: 0.00023021273106190593\n",
      "迭代第 100 次\n",
      "代价函数上一次的差: 0.00022601936524505387\n",
      "迭代第 101 次\n",
      "代价函数上一次的差: 0.00022194107125277432\n",
      "迭代第 102 次\n",
      "代价函数上一次的差: 0.00021797365802761134\n",
      "迭代第 103 次\n",
      "代价函数上一次的差: 0.000214113123898952\n",
      "迭代第 104 次\n",
      "代价函数上一次的差: 0.00021035564640125085\n",
      "迭代第 105 次\n",
      "代价函数上一次的差: 0.00020669757272519587\n",
      "迭代第 106 次\n",
      "代价函数上一次的差: 0.00020313541075701533\n",
      "迭代第 107 次\n",
      "代价函数上一次的差: 0.0001996658206652492\n",
      "迭代第 108 次\n",
      "代价函数上一次的差: 0.00019628560699680442\n",
      "迭代第 109 次\n",
      "代价函数上一次的差: 0.00019299171124741166\n",
      "迭代第 110 次\n",
      "代价函数上一次的差: 0.00018978120487449235\n",
      "迭代第 111 次\n",
      "代价函数上一次的差: 0.00018665128272203624\n",
      "迭代第 112 次\n",
      "代价函数上一次的差: 0.00018359925683096925\n",
      "迭代第 113 次\n",
      "代价函数上一次的差: 0.00018062255060797422\n",
      "迭代第 114 次\n",
      "代价函数上一次的差: 0.00017771869333082016\n",
      "迭代第 115 次\n",
      "代价函数上一次的差: 0.00017488531496662532\n",
      "迭代第 116 次\n",
      "代价函数上一次的差: 0.00017212014128443337\n",
      "迭代第 117 次\n",
      "代价函数上一次的差: 0.0001694209892417163\n",
      "迭代第 118 次\n",
      "代价函数上一次的差: 0.0001667857626282583\n",
      "迭代第 119 次\n",
      "代价函数上一次的差: 0.00016421244795131532\n",
      "迭代第 120 次\n",
      "代价函数上一次的差: 0.0001616991105458064\n",
      "迭代第 121 次\n",
      "代价函数上一次的差: 0.0001592438908967972\n",
      "迭代第 122 次\n",
      "代价函数上一次的差: 0.00015684500116053615\n",
      "迭代第 123 次\n",
      "代价函数上一次的差: 0.00015450072187201888\n",
      "迭代第 124 次\n",
      "代价函数上一次的差: 0.00015220939882748183\n",
      "迭代第 125 次\n",
      "代价函数上一次的差: 0.00014996944013175376\n",
      "迭代第 126 次\n",
      "代价函数上一次的差: 0.00014777931340031678\n",
      "迭代第 127 次\n",
      "代价函数上一次的差: 0.0001456375431067823\n",
      "迭代第 128 次\n",
      "代价函数上一次的差: 0.00014354270806739983\n",
      "迭代第 129 次\n",
      "代价函数上一次的差: 0.00014149343905437914\n",
      "迭代第 130 次\n",
      "代价函数上一次的差: 0.00013948841653113608\n",
      "迭代第 131 次\n",
      "代价函数上一次的差: 0.0001375263685008815\n",
      "迭代第 132 次\n",
      "代价函数上一次的差: 0.00013560606846448747\n",
      "迭代第 133 次\n",
      "代价函数上一次的差: 0.00013372633347893265\n",
      "迭代第 134 次\n",
      "代价函数上一次的差: 0.00013188602231233373\n",
      "迭代第 135 次\n",
      "代价函数上一次的差: 0.00013008403368915122\n",
      "迭代第 136 次\n",
      "代价函数上一次的差: 0.00012831930462162827\n",
      "迭代第 137 次\n",
      "代价函数上一次的差: 0.00012659080882099563\n",
      "迭代第 138 次\n",
      "代价函数上一次的差: 0.00012489755518623954\n",
      "迭代第 139 次\n",
      "代价函数上一次的差: 0.00012323858636395166\n",
      "迭代第 140 次\n",
      "代价函数上一次的差: 0.00012161297737739094\n",
      "迭代第 141 次\n",
      "代价函数上一次的差: 0.00012001983431931748\n",
      "迭代第 142 次\n",
      "代价函数上一次的差: 0.00011845829310698497\n",
      "迭代第 143 次\n",
      "代价函数上一次的差: 0.00011692751829384465\n",
      "迭代第 144 次\n",
      "代价函数上一次的差: 0.000115426701937104\n",
      "迭代第 145 次\n",
      "代价函数上一次的差: 0.00011395506251672335\n",
      "迭代第 146 次\n",
      "代价函数上一次的差: 0.00011251184390390079\n",
      "迭代第 147 次\n",
      "代价函数上一次的差: 0.00011109631437594691\n",
      "迭代第 148 次\n",
      "代价函数上一次的差: 0.00010970776567607865\n",
      "迭代第 149 次\n",
      "代价函数上一次的差: 0.00010834551211462082\n",
      "迭代第 150 次\n",
      "代价函数上一次的差: 0.00010700888971036313\n",
      "迭代第 151 次\n",
      "代价函数上一次的差: 0.000105697255370088\n",
      "迭代第 152 次\n",
      "代价函数上一次的差: 0.00010440998610353885\n",
      "迭代第 153 次\n",
      "代价函数上一次的差: 0.0001031464782731209\n",
      "迭代第 154 次\n",
      "代价函数上一次的差: 0.00010190614687585753\n",
      "迭代第 155 次\n",
      "代价函数上一次的差: 0.00010068842485615181\n",
      "代价函数迭代到最小值，退出!\n",
      "收敛到: 0.01783515154575959\n",
      "偏置项: 0.946640448171521\n",
      "一阶权重值: [0.26066222 0.31971331 0.474014   0.5066876 ]\n",
      "二阶组合特征权重值: [-0.62764041  0.1541043   0.25688123  0.08111611  0.2113728   0.27469023]\n",
      "测试集准确度: 1.0\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "X = X[y!=2]\n",
    "y = y[y!=2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "myPoly = POLY2()\n",
    "myPoly.fit(X_train, y_train)\n",
    "y_predict = myLogistic.predict(X_test)\n",
    "\n",
    "print('偏置项:', myPoly.b)\n",
    "print('一阶权重值:', myPoly.W)\n",
    "print('二阶组合特征权重值:', myPoly.W_join)\n",
    "print('测试集准确度:', myPoly.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
