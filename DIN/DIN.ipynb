{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseFeature(feat, feat_num, embed_dim=4):\n",
    "    return {'feat':feat, 'feat_num':feat_num, 'embed_dim':embed_dim}\n",
    "def denseFeature(feat):\n",
    "    return {'feat':feat}\n",
    "def create_amazon_electronic_dataset(file, embed_dim=8, maxlen=40):\n",
    "\t\"\"\"\n",
    "\t:param file: dataset path\n",
    "\t:param embed_dim: latent factor\n",
    "\t:param maxlen\n",
    "\t:return: user_num, item_num, train_df, test_df\n",
    "\t\"\"\"\n",
    "\tprint('=========Data Preprocess Start===========')\n",
    "\twith open(file, 'rb') as f:\n",
    "\t\treviews_df = pickle.load(f)\n",
    "\t\tcate_list = pickle.load(f)\n",
    "\t\tuser_count, item_count, cate_count, example_count = pickle.load(f)\n",
    "\treviews_df = reviews_df\n",
    "\treviews_df.columns = ['user_id', 'item_id', 'time']\n",
    "\n",
    "\ttrain_data, val_data, test_data = [], [], []\n",
    "\n",
    "\tfor user_id, hist in tqdm(reviews_df.groupby('user_id')):\n",
    "\t\tpos_list = hist['item_id'].tolist()             # pos_list就是用户真实购买的商品， 下面针对每个购买的商品， 产生一个用户没有购买过的产品\n",
    "\n",
    "\t\tdef gen_neg():\n",
    "\t\t\tneg = pos_list[0]\n",
    "\t\t\twhile neg in pos_list: \n",
    "\t\t\t\tneg = random.randint(0, item_count-1)       # 这儿产生一个不在真实用户购买的里面的\n",
    "\t\t\treturn neg\n",
    "\t\tneg_list = [gen_neg() for i in range(len(pos_list))]\n",
    "\t\thist = []\n",
    "\t\tfor i in range(1, len(pos_list)):\n",
    "\t\t\thist.append([pos_list[i-1]])\n",
    "\t\t\tif i == len(pos_list) - 1:                   # 最后一个的时候\n",
    "\t\t\t\ttest_data.append([hist, [pos_list[i]], 1])\n",
    "\t\t\t\ttest_data.append([hist, [neg_list[i]], 0])\n",
    "\t\t\telif i == len(pos_list) - 2:           # 倒数第二个的时候\n",
    "\t\t\t\tval_data.append([hist, [pos_list[i]], 1])\n",
    "\t\t\t\tval_data.append([hist, [neg_list[i]], 0])\n",
    "\t\t\telse:\n",
    "\t\t\t\ttrain_data.append([hist, [pos_list[i]], 1])\n",
    "\t\t\t\ttrain_data.append([hist, [neg_list[i]], 0])\n",
    "\n",
    "\t# feature columns\n",
    "\tfeature_columns = [\n",
    "\t\t[],\n",
    "\t\t[sparseFeature('item_id', item_count, embed_dim)]\n",
    "\t]\n",
    "\n",
    "\t# behavior_list\n",
    "\tbehavior_list = ['item_id']\n",
    "\n",
    "\t# shuffle\n",
    "\trandom.shuffle(train_data)\n",
    "\trandom.shuffle(val_data)\n",
    "\trandom.shuffle(test_data)\n",
    "\n",
    "\ttrain = pd.DataFrame(train_data, columns=['hist', 'target_item', 'label'])\n",
    "\tval = pd.DataFrame(val_data, columns=['hist', 'target_item', 'label'])\n",
    "\ttest = pd.DataFrame(test_data, columns=['hist', 'target_item', 'label'])\n",
    "\n",
    "\t# if no dense or sparse features, can fill with 0\n",
    "\tprint('=================Padding================')\n",
    "\n",
    "\n",
    "\n",
    "\ttrain_X = [np.array([0.] * len(train)), np.array([0]*len(train)), pad_sequences(train['hist'], maxlen=maxlen), np.array(train['target_item'].tolist())]\n",
    "\ttrain_y = train['label'].values\n",
    "\tval_X = [np.array([0.] * len(val)), np.array([0]*len(val)), pad_sequences(val['hist'], maxlen=maxlen), np.array(val['target_item'].tolist())]\n",
    "\tval_y = val['label'].values\n",
    "\ttest_X = [np.array([0.] * len(test)), np.array([0]*len(test)), pad_sequences(test['hist'], maxlen=maxlen), np.array(test['target_item'].tolist())]\n",
    "\ttest_y = test['label'].values\n",
    "\tprint('===========Data Preprocess End====================')\n",
    "\treturn feature_columns, behavior_list, (train_X, train_y), (val_X, val_y), (test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Data Preprocess Start===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:14<00:00, 7088.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Padding================\n",
      "===========Data Preprocess End====================\n"
     ]
    }
   ],
   "source": [
    "file_name = './remap.pkl'\n",
    "feature_columns, behavior_list, (train_X, train_y), (val_X, val_y), (test_X, test_y) = create_amazon_electronic_dataset(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(528800,)\n",
      "(528800,)\n",
      "(528800, 40, 1)\n",
      "(528800, 1)\n",
      "(528800,)\n",
      "(159746,)\n",
      "(184778,)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))\n",
    "print(train_X[0].shape)\n",
    "print(train_X[1].shape)\n",
    "print(train_X[2].shape)\n",
    "print(train_X[3].shape)\n",
    "print(train_y.shape)\n",
    "print(val_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [{'feat': 'item_id', 'feat_num': 37392, 'embed_dim': 8}]] ['item_id']\n"
     ]
    }
   ],
   "source": [
    "print(feature_columns, behavior_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([10000, 1]) torch.Size([10000, 1]) torch.Size([10000, 40, 1]) torch.Size([10000, 1]) tensor([0., 1., 1.,  ..., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "dl_train_dataset = TensorDataset(torch.tensor(train_X[0].reshape(-1,1)).float(), torch.tensor(train_X[1].reshape(-1,1)).float(), torch.tensor(train_X[2]).float(), torch.tensor(train_X[3]).float(), torch.tensor(train_y).float())\n",
    "dl_val_dataset = TensorDataset(torch.tensor(val_X[0].reshape(-1,1)).float(), torch.tensor(val_X[1].reshape(-1,1)).float(), torch.tensor(val_X[2]).float(), torch.tensor(val_X[3]).float(), torch.tensor(val_y).float())\n",
    "\n",
    "dl_train = DataLoader(dl_train_dataset, shuffle=True, batch_size=10000)\n",
    "dl_val = DataLoader(dl_val_dataset, shuffle=True, batch_size=10000)\n",
    "\n",
    "for dense_input, sparse_input, behavior_data, target_item, label in iter(dl_train):\n",
    "    print(type(dense_input))\n",
    "    print(dense_input.shape, sparse_input.shape, behavior_data.shape, target_item.shape, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_layer(nn.Module):\n",
    "    #自定义Attenion层，其实就是一个全连接神经网络\n",
    "    def __init__(self, att_hidden_units, activation='sigmoid'):\n",
    "        super(Attention_layer, self).__init__()\n",
    "        self.att_layer = nn.ModuleList([nn.Linear(layer[0], layer[1]) for layer in list(zip(att_hidden_units[:-1], att_hidden_units[1:]))])\n",
    "        self.att_final_layer = nn.Linear(att_hidden_units[-1], 1)\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        这里的inputs包含四个部分:[item_embed, seq_embed, seq_embed, mask]\n",
    "        item_embed:这个是候选商品的embedding向量，维度是(None, embedding_dim * behavior_num) #behavior_num能表示用户行为的特征个数 这里是1，所以(None, embed_dim)\n",
    "        mask: 维度是(None, max_len) 这个里面每一行是[False, False, True, True, ...]的形式，False的长度表示样本填充的那部分\n",
    "        \"\"\"\n",
    "        q, k, v, key_masks = inputs\n",
    "        q = q.repeat(1, k.shape[1])   #(None. max_len*embedding) #沿着k.shape[1]的维度复制 每个历史行为都要和当前的商品计算相似关系\n",
    "        q = torch.reshape(q, (-1, k.shape[1], k.shape[2]))   #(None, max_len, embedding_dim)\n",
    "        \n",
    "        #q, k, out product should concat\n",
    "        info = torch.cat([q, k, q-k, q*k], dim=-1) #(None, max_len, 4*embedding_dim)\n",
    "        \n",
    "        #n层全连接\n",
    "        for linear in self.att_layer:\n",
    "            info = linear(info)\n",
    "            info = F.relu(info)\n",
    "        outputs = self.att_final_layer(info)   #(None, max_len, 1)\n",
    "#         print(outputs.shape)\n",
    "        outputs = torch.squeeze(outputs, dim=-1) #(None, max_len)\n",
    "#         print(outputs.shape)\n",
    "        \n",
    "        #mask 把每个行为序列填充的那部分替换成很小的一个值\n",
    "        paddings = torch.ones_like(outputs) * (-2**32+1)    #(None, max_len)这个就是之前填充的那个地方，我们补一个很小的值\n",
    "        outputs = torch.where(key_masks==0, paddings, outputs)\n",
    "#         print(outputs.shape)\n",
    "        \n",
    "        #softmax\n",
    "        outputs = F.softmax(outputs, dim=1) #(None, max_len)\n",
    "        outputs = torch.unsqueeze(outputs, 1) #(None, 1, max_len)\n",
    "        \n",
    "        outputs = torch.matmul(outputs, v) #三维矩阵相乘，(None, 1, max_len)*(None, max_len, embed_dim) = (None,1,embed_dim)\n",
    "        outputs = torch.squeeze(outputs, dim=1)  #(None,embed_dim)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice(nn.Module):\n",
    "    def __init__(self, fea_num):\n",
    "        super(Dice, self).__init__()\n",
    "        self.fea_num = fea_num\n",
    "        self.bn = nn.BatchNorm1d(fea_num)\n",
    "        self.alpha = nn.Parameter(torch.randn(1))\n",
    "        nn.init.uniform_(self.alpha, 0, 1)\n",
    "    def forward(self, x):\n",
    "        x_normed = self.bn(x)\n",
    "        x_p = torch.sigmoid(x_normed)\n",
    "        \n",
    "        return self.alpha * (1.0-x_p) * x + x_p * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIN(nn.Module):\n",
    "    def __init__(self, feature_columns, behavior_feature_list, att_hidden_units=(80, 40), ffn_hidden_units=(80, 40), att_activation='sigmoid',\n",
    "                ffn_activation='prelu', maxlen=40, dnn_dropout=0., embed_reg=1e-4):\n",
    "        \"\"\"\n",
    "        feature_columns:列表，[dense_feature_columns, sparse_feature_columns], dense_feature_columns是[{'feat':'feat_name'}], 而sparse_feature_columns是[{'feat':'feat_name', 'feat_num':'nunique', 'embed_dim'}]\n",
    "        behavior_feature_list:列表，能表示用户历史行为的特征，比如商品id,店铺id['item', 'cat']\n",
    "        att_hidden_units:注意力层的隐藏单元个数。可以是一个列表或者元组，注意注意力层是一个全连接网络\n",
    "        ffn_hidden_units:全连接层的隐藏单元个数和层数，可以是一个列表或者元组\n",
    "        att_activation:激活单元的名称，字符串\n",
    "        ffn_activation:激活单元的名称，用'prelu'或者'Dice'\n",
    "        maxlen:标量，用户历史行为序列的最大长度\n",
    "        dropout:标量，失活率\n",
    "        embed_reg:标量，正则系数\n",
    "        \"\"\"\n",
    "        super(DIN, self).__init__() #初始化网络\n",
    "        self.maxlen = maxlen\n",
    "        self.dense_feature_columns, self.sparse_feature_columns = feature_columns #将连续特征和离散特征分别取出来，因为这两者后期的处理不同\n",
    "        \n",
    "        #len\n",
    "        self.other_sparse_len = len(self.sparse_feature_columns) - len(behavior_feature_list) #这个other_sparse_len就是离散特征中去掉了能表示用户行为的特征列\n",
    "        self.dense_len = len(self.dense_feature_columns)\n",
    "        self.behavior_num = len(behavior_feature_list)\n",
    "        \n",
    "        self.fea_num = 0\n",
    "        if self.other_sparse_len > 0 or self.dense_len > 0:\n",
    "            self.fea_num = self.dense_len + self.other_sparse_len + self.sparse_feature_columns[0]['embed_dim'] * 2\n",
    "        else:\n",
    "            self.fea_num = self.sparse_feature_columns[0]['embed_dim'] * 2\n",
    "        #embedding层，这里分成两部分的embedding，第一部分是普通的离散特征，第二部分是能表示用户历史行为的离散特征，这一块后面要进注意力和当前的商品计算相关性\n",
    "        self.embed_sparse_layers = nn.ModuleList([nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for feat in self.sparse_feature_columns if feat['feat'] not in behavior_feature_list])\n",
    "        \n",
    "        #behavior embedding layers, item id and category id\n",
    "        self.embed_seq_layers = nn.ModuleList([nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for feat in self.sparse_feature_columns if feat['feat'] in behavior_feature_list])\n",
    "        \n",
    "        #注意力机制\n",
    "        att_hidden_units.insert(0, self.sparse_feature_columns[0]['embed_dim'] * 4)\n",
    "        self.attention_layer = Attention_layer(att_hidden_units, att_activation)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(self.fea_num)\n",
    "        \n",
    "        #全连接网络\n",
    "        self.ffn_activation = ffn_activation\n",
    "        ffn_hidden_units.insert(0, self.fea_num)\n",
    "        self.ffn = nn.ModuleList(nn.Linear(layer[0], layer[1]) for layer in list(zip(ffn_hidden_units[:-1], ffn_hidden_units[1:])))\n",
    "        self.dropout = nn.Dropout(dnn_dropout)\n",
    "        self.final_fnn_layer = nn.Linear(ffn_hidden_units[-1], 1)\n",
    "        \n",
    "        #dice\n",
    "        self.dice_fea_nums = ffn_hidden_units[1:]\n",
    "        self.dice = nn.ModuleList(Dice(dice_fea_num) for dice_fea_num in self.dice_fea_nums)\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs:[dense_inputs, sparse_input, seq_input, item_input],第二部分是离散型的特征输入，第三部分是用户的历史行为，第四部分是当前商品的输入\n",
    "        dense_input:连续型的特征输入,维度是(None, dense_len)\n",
    "        sparse_input:离散型的特征输入,维度是(None, other_sparse_len)\n",
    "        seq_input:用户的历史行为xulie(None, maxlen, behavior_len)\n",
    "        item_input:当前的候选商品序列(None, behavior_len)\n",
    "        \"\"\"\n",
    "        dense_inputs, sparse_inputs, seq_inputs, item_inputs = inputs\n",
    "        sparse_inputs = sparse_inputs.long()\n",
    "        seq_inputs = seq_inputs.long()\n",
    "        item_inputs = item_inputs.long()\n",
    "        \n",
    "        #attention ----> mask, if the element of seq_inputs is equal 0, it must be filled in \n",
    "        mask = torch.tensor(seq_inputs[:,:,0]!=0, dtype=torch.float32)  #(None, maxlen)类型转换函数，把seq_input中不等于0的值转成float32\n",
    "        #这个函数的作用就是每一行样本中，不为0的值返回1，为0的值返回0，这样就把填充的那部分值都给标记了出来\n",
    "        \n",
    "        #下面把连续型特征和行为无关的离散型特征拼到一起先\n",
    "        other_info = dense_inputs  #(None, dense_len)\n",
    "        for i in range(self.other_sparse_len):\n",
    "            other_info = torch.cat([other_info, self.embed_sparse_layers[i](sparse_inputs[:,i])], dim=-1) #(None, dense_len+other_sparse_len)\n",
    "        \n",
    "        #下面把候选的商品和用户行为商品也各自的拼接起来\n",
    "        seq_embed = torch.cat([self.embed_seq_layers[i](seq_inputs[:,:,i]) for i in range(self.behavior_num)], dim=-1)#(None, max_len, embed_dim)\n",
    "        item_embed = torch.cat([self.embed_seq_layers[i](item_inputs[:, i]) for i in range(self.behavior_num)],dim=-1) #(None, embed_dim)\n",
    "        \n",
    "        #下面进行attention_layer的计算\n",
    "        user_info = self.attention_layer([item_embed, seq_embed, seq_embed, mask]) #(None, embed_dim)\n",
    "        \n",
    "        #所有特征拼接起来\n",
    "        if self.dense_len > 0 or self.other_sparse_len > 0:\n",
    "            info_all = torch.cat([user_info, item_embed, other_info], dim=-1) #(None, dense_len+other_sparse_len+embed_dim+embed_dim)\n",
    "        else:\n",
    "            info_all = torch.cat([user_info, item_embed], dim=-1) #(None, embed_dim+embed_dim)\n",
    "        \n",
    "        info_all = self.bn(info_all)\n",
    "        \n",
    "        #ffn\n",
    "        dice_i = 0\n",
    "        for linear in self.ffn:\n",
    "            info_all = linear(info_all)\n",
    "            if self.ffn_activation == 'prelu':\n",
    "                activation_func = nn.PReLU(num_parameters=1)\n",
    "                info_all = activation_func(info_all)\n",
    "            else:\n",
    "                info_all = self.dice[dice_i](info_all)\n",
    "                dice_i += 1\n",
    "        info_all = self.dropout(info_all)\n",
    "        outputs = torch.sigmoid(self.final_fnn_layer(info_all))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIN(\n",
       "  (embed_sparse_layers): ModuleList()\n",
       "  (embed_seq_layers): ModuleList(\n",
       "    (0): Embedding(37392, 8)\n",
       "  )\n",
       "  (attention_layer): Attention_layer(\n",
       "    (att_layer): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=80, bias=True)\n",
       "      (1): Linear(in_features=80, out_features=40, bias=True)\n",
       "    )\n",
       "    (att_final_layer): Linear(in_features=40, out_features=1, bias=True)\n",
       "  )\n",
       "  (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ffn): ModuleList(\n",
       "    (0): Linear(in_features=16, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (final_fnn_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dice): ModuleList(\n",
       "    (0): Dice(\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Dice(\n",
       "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Dice(\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建立模型\n",
    "maxlen = 40\n",
    "embed_dim = 8\n",
    "att_hidden_units = [80, 40]\n",
    "ffn_hidden_units = [256, 128, 64]\n",
    "dnn_dropout = 0.5\n",
    "att_activation = 'sigmoid'\n",
    "ffn_activation = 'dice'\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "model = DIN(feature_columns, behavior_list, att_hidden_units, ffn_hidden_units, att_activation, ffn_activation, maxlen, dnn_dropout)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4773],\n",
      "        [0.4883],\n",
      "        [0.4961],\n",
      "        [0.4883],\n",
      "        [0.4893],\n",
      "        [0.4764],\n",
      "        [0.4899],\n",
      "        [0.4837],\n",
      "        [0.4563],\n",
      "        [0.4416],\n",
      "        [0.5039],\n",
      "        [0.5024],\n",
      "        [0.4543],\n",
      "        [0.4623],\n",
      "        [0.4558],\n",
      "        [0.4797],\n",
      "        [0.4464],\n",
      "        [0.4596],\n",
      "        [0.4928],\n",
      "        [0.4748],\n",
      "        [0.4738],\n",
      "        [0.4615],\n",
      "        [0.4493],\n",
      "        [0.4704],\n",
      "        [0.5107],\n",
      "        [0.4646],\n",
      "        [0.4695],\n",
      "        [0.4568],\n",
      "        [0.4543],\n",
      "        [0.4671],\n",
      "        [0.4659],\n",
      "        [0.4743]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "#测试一下模型\n",
    "for dense_input, sparse_input, behavior_input, target_item, label in iter(dl_train):\n",
    "    out = model([dense_input, sparse_input, behavior_input, target_item])\n",
    "    print(out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_pred, y_true):\n",
    "    pred = y_pred.data\n",
    "    y = y_true.data\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "metric_func = auc\n",
    "metric_name = 'auc'\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_training.........\n",
      "================================================================2022-08-11 16:15:28\n",
      "[step=10] loss: 0.051, auc: 0.995\n",
      "[step=20] loss: 0.050, auc: 0.995\n",
      "[step=30] loss: 0.050, auc: 0.995\n",
      "[step=40] loss: 0.050, auc: 0.995\n",
      "[step=50] loss: 0.050, auc: 0.995\n",
      "\n",
      "EPOCH=1, loss=0.050, auc = 0.995, val_loss=0.006, val_auc = 1.000\n",
      "\n",
      "================================================================================2022-08-11 16:16:51\n",
      "[step=10] loss: 0.051, auc: 0.995\n",
      "[step=20] loss: 0.050, auc: 0.995\n",
      "[step=30] loss: 0.050, auc: 0.995\n",
      "[step=40] loss: 0.050, auc: 0.996\n",
      "[step=50] loss: 0.050, auc: 0.996\n",
      "\n",
      "EPOCH=2, loss=0.050, auc = 0.996, val_loss=0.006, val_auc = 1.000\n",
      "\n",
      "================================================================================2022-08-11 16:18:13\n",
      "[step=10] loss: 0.048, auc: 0.996\n",
      "[step=20] loss: 0.049, auc: 0.996\n",
      "[step=30] loss: 0.048, auc: 0.996\n",
      "[step=40] loss: 0.048, auc: 0.996\n",
      "[step=50] loss: 0.049, auc: 0.996\n",
      "\n",
      "EPOCH=3, loss=0.049, auc = 0.996, val_loss=0.006, val_auc = 1.000\n",
      "\n",
      "================================================================================2022-08-11 16:19:34\n",
      "[step=10] loss: 0.048, auc: 0.996\n",
      "[step=20] loss: 0.048, auc: 0.996\n",
      "[step=30] loss: 0.048, auc: 0.996\n",
      "[step=40] loss: 0.048, auc: 0.996\n",
      "[step=50] loss: 0.048, auc: 0.996\n",
      "\n",
      "EPOCH=4, loss=0.048, auc = 0.996, val_loss=0.006, val_auc = 1.000\n",
      "\n",
      "================================================================================2022-08-11 16:20:56\n",
      "[step=10] loss: 0.047, auc: 0.996\n",
      "[step=20] loss: 0.047, auc: 0.996\n",
      "[step=30] loss: 0.046, auc: 0.996\n",
      "[step=40] loss: 0.047, auc: 0.996\n",
      "[step=50] loss: 0.047, auc: 0.996\n",
      "\n",
      "EPOCH=5, loss=0.047, auc = 0.996, val_loss=0.006, val_auc = 1.000\n",
      "\n",
      "================================================================================2022-08-11 16:22:17\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "log_step_freq = 10\n",
    "\n",
    "dfhistory = pd.DataFrame(columns=['epoch', 'loss', metric_name, 'val_loss', 'val_'+metric_name])\n",
    "\n",
    "print('start_training.........')\n",
    "nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('========'*8 + '%s' %nowtime)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    metric_sum = 0.0\n",
    "    step = 1\n",
    "    \n",
    "    for step, (dense_input, sparse_input, behavior_input, target_item, labels) in enumerate(dl_train, 1):\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 正向传播\n",
    "        predictions = model([dense_input, sparse_input, behavior_input, target_item])\n",
    "        loss = loss_func(predictions, labels)\n",
    "        try:\n",
    "            metric = metric_func(predictions, labels)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印batch级别日志\n",
    "        loss_sum += loss.item()\n",
    "        metric_sum += metric.item()\n",
    "        if step % log_step_freq == 0:\n",
    "            print((\"[step=%d] loss: %.3f, \" + metric_name + \": %.3f\") % (step, loss_sum/step, metric_sum/step));\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "    \n",
    "    for val_step, (dense_input, sparse_input, behavior_input, target_item, labels) in enumerate(dl_val, 1):\n",
    "        with torch.no_grad():\n",
    "            predictions = model([dense_input, sparse_input, behavior_input, target_item])\n",
    "            val_loss = loss_func(predictions, labels)\n",
    "            try:\n",
    "                val_metric = metric_func(predictions, labels)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_metric_sum += val_metric.item()\n",
    "    \n",
    "    # 记录日志\n",
    "    info = (epoch, loss_sum/step, metric_sum/step, val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "    dfhistory.loc[epoch-1] = info\n",
    "    \n",
    "    # 打印日志\n",
    "    print((\"\\nEPOCH=%d, loss=%.3f, \" + metric_name + \" = %.3f, val_loss=%.3f, \" + \"val_\" + metric_name + \" = %.3f\") %info)\n",
    "    nowtime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print('\\n' + '=========='* 8 + '%s' %nowtime)\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 观察损失和准确率的变化\n",
    "plot_metric(dfhistory,\"loss\")\n",
    "plot_metric(dfhistory,\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_auc:0.504, test_acc:0.500\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "y_pred_probs = model([torch.tensor(test_X[0].reshape(-1,1)).float(), torch.tensor(test_X[1].reshape(-1,1)).float(), torch.tensor(test_X[2]).float(), torch.tensor(test_X[3]).float()])\n",
    "y_pred = torch.where(y_pred_probs>0.5, torch.ones_like(y_pred_probs), torch.zeros_like(y_pred_probs))\n",
    "test_auc = auc(y_pred_probs.data.numpy(), test_y)\n",
    "test_acc = accuracy_score(test_y, y_pred.data.numpy())\n",
    "print('test_auc:%.3f, test_acc:%.3f'%(test_auc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
