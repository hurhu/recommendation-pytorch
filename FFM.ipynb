{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseFeature(feat, feat_onehot_dim, embed_dim):\n",
    "    return {'feat':feat, 'feat_onehot_dim':feat_onehot_dim, 'embed_dim':embed_dim}\n",
    "def denseFeature(feat):\n",
    "    return {'feat':feat}\n",
    "def create_criteo_dataset(file_path, embed_dim=8, test_size=0.2):\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "    \n",
    "    #缺失值填充\n",
    "    data[dense_features] = data[dense_features].fillna(0)\n",
    "    data[sparse_features] = data[sparse_features].fillna('-1')\n",
    "    \n",
    "    #归一化\n",
    "    data[dense_features] = MinMaxScaler().fit_transform(data[dense_features])\n",
    "    #LabelEncoding编码\n",
    "    for col in sparse_features:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col]).astype(int)\n",
    "    \n",
    "    feature_columns = [[denseFeature(feat) for feat in dense_features]] + \\\n",
    "    [[sparseFeature(feat, data[feat].nunique(), embed_dim) for feat in sparse_features]]\n",
    "    \n",
    "    X = data.drop(['label'], axis=1).values\n",
    "    y = data['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    return feature_columns, (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 10\n",
    "num_workers = 4\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=torch.float64)\n",
      "torch.Size([10, 39])\n"
     ]
    }
   ],
   "source": [
    "feature_columns, (X_train, y_train), (X_test, y_test) = create_criteo_dataset('train.txt')\n",
    "cols = ['col' + str(i) for i in range(X_train.shape[1])]\n",
    "cols.append('label')\n",
    "\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "trains = np.concatenate((X_train, y_train), axis=1)\n",
    "train_df = pd.DataFrame(trains, columns=cols)\n",
    "\n",
    "tests = np.concatenate((X_test, y_test), axis=1)\n",
    "test_df = pd.DataFrame(tests, columns=cols)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        cols = df.columns.tolist()\n",
    "        cols.remove('label')\n",
    "        self.X = df.loc[:, cols].values\n",
    "        self.y = df.loc[:, 'label'].values\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        data_x = self.X[idx]\n",
    "        data_y = self.y[idx]\n",
    "        return data_x, data_y\n",
    "\n",
    "train_data = MyDataset(train_df)\n",
    "test_data = MyDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "iter_x, iter_y = next(iter(train_loader))\n",
    "print(iter_y)\n",
    "print(iter_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'feat': 'I1'}, {'feat': 'I2'}, {'feat': 'I3'}, {'feat': 'I4'}, {'feat': 'I5'}, {'feat': 'I6'}, {'feat': 'I7'}, {'feat': 'I8'}, {'feat': 'I9'}, {'feat': 'I10'}, {'feat': 'I11'}, {'feat': 'I12'}, {'feat': 'I13'}], [{'feat': 'C1', 'feat_onehot_dim': 79, 'embed_dim': 8}, {'feat': 'C2', 'feat_onehot_dim': 252, 'embed_dim': 8}, {'feat': 'C3', 'feat_onehot_dim': 1293, 'embed_dim': 8}, {'feat': 'C4', 'feat_onehot_dim': 1043, 'embed_dim': 8}, {'feat': 'C5', 'feat_onehot_dim': 30, 'embed_dim': 8}, {'feat': 'C6', 'feat_onehot_dim': 7, 'embed_dim': 8}, {'feat': 'C7', 'feat_onehot_dim': 1164, 'embed_dim': 8}, {'feat': 'C8', 'feat_onehot_dim': 39, 'embed_dim': 8}, {'feat': 'C9', 'feat_onehot_dim': 2, 'embed_dim': 8}, {'feat': 'C10', 'feat_onehot_dim': 908, 'embed_dim': 8}, {'feat': 'C11', 'feat_onehot_dim': 926, 'embed_dim': 8}, {'feat': 'C12', 'feat_onehot_dim': 1239, 'embed_dim': 8}, {'feat': 'C13', 'feat_onehot_dim': 824, 'embed_dim': 8}, {'feat': 'C14', 'feat_onehot_dim': 20, 'embed_dim': 8}, {'feat': 'C15', 'feat_onehot_dim': 819, 'embed_dim': 8}, {'feat': 'C16', 'feat_onehot_dim': 1159, 'embed_dim': 8}, {'feat': 'C17', 'feat_onehot_dim': 9, 'embed_dim': 8}, {'feat': 'C18', 'feat_onehot_dim': 534, 'embed_dim': 8}, {'feat': 'C19', 'feat_onehot_dim': 201, 'embed_dim': 8}, {'feat': 'C20', 'feat_onehot_dim': 4, 'embed_dim': 8}, {'feat': 'C21', 'feat_onehot_dim': 1204, 'embed_dim': 8}, {'feat': 'C22', 'feat_onehot_dim': 7, 'embed_dim': 8}, {'feat': 'C23', 'feat_onehot_dim': 12, 'embed_dim': 8}, {'feat': 'C24', 'feat_onehot_dim': 729, 'embed_dim': 8}, {'feat': 'C25', 'feat_onehot_dim': 33, 'embed_dim': 8}, {'feat': 'C26', 'feat_onehot_dim': 554, 'embed_dim': 8}]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMLayer(nn.Module):\n",
    "    def __init__(self, feature_columns, k, w_reg=1e-4, v_reg=1e-4):\n",
    "        super(FFMLayer, self).__init__()\n",
    "        self.dense_feature_columns, self.sparse_feature_columns = feature_columns\n",
    "        self.k = k  #隐向量v的维度\n",
    "        self.w_reg = w_reg  #一阶权重w的正则化项\n",
    "        self.v_reg = v_reg  #二阶组合特征权重的正则化项\n",
    "        \n",
    "        #真实的特征维度是：类别型变量做了one hot之后的维度加连续型变量的维度\n",
    "        self.feature_num = sum([feat['feat_onehot_dim'] for feat in self.sparse_feature_columns]) + len(self.dense_feature_columns)\n",
    "        #域个数是原始特征的个数，一个特征属于一个域\n",
    "        self.field_num = len(self.dense_feature_columns) + len(self.sparse_feature_columns)\n",
    "        \n",
    "        #一阶线性部分\n",
    "        self.linear = nn.Linear(self.feature_num, 1)\n",
    "        self.v = nn.Parameter(torch.randn(self.feature_num, self.field_num, k)) #二阶特征组合的交互矩阵\n",
    "    def ffm_layer(self, inputs):\n",
    "        #x的维度是(batch_size, 26):离散特征个数加连续特征个数，离散特征还没有做Onehot\n",
    "        dense_input = inputs[:, :13]\n",
    "        sparse_inputs = inputs[:, 13:]\n",
    "        \n",
    "        #做One hot编码 将连续特征和one hot后的特征拼接成为每个样本新的特征\n",
    "        x = dense_input.to(dtype=torch.float32)\n",
    "        for i in range(sparse_inputs.shape[1]):\n",
    "            one_hot_value = F.one_hot(sparse_inputs[:,i].to(dtype=torch.int64), num_classes=int(self.sparse_feature_columns[i]['feat_onehot_dim']))\n",
    "            x = torch.cat([x, one_hot_value.to(dtype=torch.float32)], 1)\n",
    "        linear_part = self.linear(x)\n",
    "        inter_part = 0\n",
    "        #每维特征先跟自己的[field_num, k]相乘得到Vij*X  [None, 2291] x [2291, 39, 8] = [None, 39, 8]\n",
    "        field_f = torch.tensordot(x, self.v, dims=1)\n",
    "        #域之间两两相乘\n",
    "        for i in range(self.field_num):\n",
    "            for j in range(i+1, self.field_num):\n",
    "                inter_part += torch.sum(torch.mul(field_f[:, i], field_f[:, j]), 1, keepdims=True)\n",
    "        output = linear_part + inter_part\n",
    "        output = output.reshape(-1)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output.to(dtype=torch.float64)\n",
    "    def forward(self, x):\n",
    "        return self.ffm_layer(x)\n",
    "    def fit(self, data, optimizer, epochs=100):\n",
    "        #训练模型并输出测试集每一轮的loss\n",
    "        criterion = F.binary_cross_entropy\n",
    "        for epoch in range(epochs):\n",
    "            for t, (batch_x, batch_y) in enumerate(data):\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                total = self.forward(batch_x)\n",
    "                loss = criterion(total, batch_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loader_test = DataLoader(test_data, batch_size=10, shuffle=False)\n",
    "            \n",
    "            r = self.test(loader_test)\n",
    "            print('Epoch %d, loss=%.4f' % (epoch, r))\n",
    "    def test(self, data):\n",
    "        #测试集测试\n",
    "        criterion = F.binary_cross_entropy\n",
    "        all_loss = 0\n",
    "        gt_labels = []\n",
    "        pred_labels = []\n",
    "        i = 0\n",
    "        with torch.no_grad():\n",
    "            for t, (batch_x, batch_y) in enumerate(data):\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                pred = self.forward(batch_x)\n",
    "                gt_label = batch_y.cpu().data.numpy()\n",
    "                pred_proba = pred.cpu().data.numpy()\n",
    "                gt_labels.append(gt_label)\n",
    "                pred_labels.append(pred_proba)\n",
    "                loss = criterion(pred, batch_y)\n",
    "                all_loss += loss.item()\n",
    "                i += 1\n",
    "        gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "        pred_labels = pred_labels.reshape(len(pred_labels),)\n",
    "        auc = roc_auc_score(gt_labels, pred_labels)\n",
    "        print('auc:', auc, 'gt_lables:', gt_labels.shape, 'pred_labels:', pred_labels.shape)\n",
    "        return all_loss / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.4523306544202067 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 0, loss=48.2720\n",
      "auc: 0.45086107921928814 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 1, loss=48.5259\n",
      "auc: 0.4523995407577497 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 2, loss=47.9334\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 3, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 4, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 5, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 6, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 7, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 8, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 9, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 10, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 11, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 12, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 13, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 14, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 15, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 16, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 17, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 18, loss=47.6678\n",
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n",
      "Epoch 19, loss=47.6678\n"
     ]
    }
   ],
   "source": [
    "k = 8\n",
    "ffm = FFMLayer(feature_columns, k)\n",
    "ffm = ffm.to(device)\n",
    "optimizer = optim.Adam(ffm.parameters(), lr=lr, weight_decay=0.0)\n",
    "ffm.fit(train_loader, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.4529735935706085 gt_lables: (400,) pred_labels: (400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.667790233367285"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffm.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit",
   "language": "python",
   "name": "python3610jvsc74a57bd084ab1d9b463ebc84275a65512ad7a16f147e3a45a7033d2cbe29a924419645af"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
