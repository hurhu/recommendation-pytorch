{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133e0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf402ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp  \\\n",
       "0        1      1193       5  978300760   \n",
       "1        1       661       3  978302109   \n",
       "2        1       914       3  978301968   \n",
       "3        1      3408       4  978300275   \n",
       "4        1      2355       5  978824291   \n",
       "\n",
       "                                    title                        genres  \\\n",
       "0  One Flew Over the Cuckoo's Nest (1975)                         Drama   \n",
       "1        James and the Giant Peach (1996)  Animation|Children's|Musical   \n",
       "2                     My Fair Lady (1964)               Musical|Romance   \n",
       "3                  Erin Brockovich (2000)                         Drama   \n",
       "4                    Bug's Life, A (1998)   Animation|Children's|Comedy   \n",
       "\n",
       "  gender  age  occupation    zip  \n",
       "0      F    1          10  48067  \n",
       "1      F    1          10  48067  \n",
       "2      F    1          10  48067  \n",
       "3      F    1          10  48067  \n",
       "4      F    1          10  48067  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./ml-1m_sample.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a055f270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>cate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp  \\\n",
       "0        1      1193       5  978300760   \n",
       "1        1       661       3  978302109   \n",
       "2        1       914       3  978301968   \n",
       "3        1      3408       4  978300275   \n",
       "4        1      2355       5  978824291   \n",
       "\n",
       "                                    title                        genres  \\\n",
       "0  One Flew Over the Cuckoo's Nest (1975)                         Drama   \n",
       "1        James and the Giant Peach (1996)  Animation|Children's|Musical   \n",
       "2                     My Fair Lady (1964)               Musical|Romance   \n",
       "3                  Erin Brockovich (2000)                         Drama   \n",
       "4                    Bug's Life, A (1998)   Animation|Children's|Comedy   \n",
       "\n",
       "  gender  age  occupation    zip    cate_id  \n",
       "0      F    1          10  48067      Drama  \n",
       "1      F    1          10  48067  Animation  \n",
       "2      F    1          10  48067    Musical  \n",
       "3      F    1          10  48067      Drama  \n",
       "4      F    1          10  48067  Animation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cate_id'] = data['genres'].apply(lambda x:x.split('|')[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51620be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sample(items_cnt_order, ratio, method_id=0):\n",
    "    \"\"\"negative sample method for matching model\n",
    "    items_cnt_order(dict):the item count dict, the keys(item) sorted by value(count) in reverse order.\n",
    "    ratio(int):negative sample ratio, >=1\n",
    "    method_id(int, optional):\n",
    "        {\n",
    "        0:'random sampling',\n",
    "        1:'popularity sampling method used in word2vec',\n",
    "        2:'popularity sampling method by 'log(count+1)+1e-6' ',\n",
    "        3:'tencent RALM sampling'\n",
    "        defaults to 0\n",
    "        }\n",
    "    \n",
    "    returns:\n",
    "       list:sampled negative item list\n",
    "    \"\"\"\n",
    "    items_set = [item for item, count in items_cnt_order.items()]\n",
    "    if method_id == 0:\n",
    "        neg_items = np.random.choice(items_set, size=ratio, replace=True)\n",
    "    elif method_id == 1:\n",
    "        p_sel = {item: count**0.75 for item, count in items_cnt_order.items()}\n",
    "        p_value = np.array(list(p_sel.values())) / sum(p_sel.values())\n",
    "        neg_items = np.random.choice(items_set, size=ratio, replace=True, p=p_value)\n",
    "    elif method_id == 2:\n",
    "        p_sel = {item:np.log(count + 1) + 1e-6 for item, count in items_cnt_order.items()}\n",
    "        p_value = np.array(list(p_sel.values())) / sum(p_sel.values())\n",
    "        neg_items = np.random.choice(items_set, size=ratio, replace=True, p=p_value)\n",
    "    elif method_id == 3:\n",
    "        p_sel = {item: (np.log(k+2) - np.log(k+1)/np.log(len(items_cnt_order)+1)) for item, k in items_cnt_order.items()}\n",
    "        p_value = np.array(list(p_sel.values())) / sum(p_sel.values())\n",
    "        neg_items = np.random.choice(items_set, size=ratio, replace=False, p=p_value)\n",
    "    else:\n",
    "        raise ValueError('method id should in (0,1,2,3)')\n",
    "    return neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61503716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "import tqdm\n",
    "import random\n",
    "def generate_seq_feature_match(data, user_col, item_col, time_col, item_attribute_cols=None, sample_method=0,\n",
    "                              mode=0, neg_ratio=0, min_item=0):\n",
    "    \"\"\"\n",
    "    generate sequence feature and negative sample for match.\n",
    "    data:the raw data\n",
    "    user_col:the col name of user_id\n",
    "    item_col:the col name of item_id\n",
    "    time_col:the col name of timestamp\n",
    "    item_attribute_cols(list[str], optional):the other attribute cols of item which you want to generate sequence\n",
    "                                             features. Defaults to '[]'\n",
    "    sample_method(int, optional):the negative sample method '{0:'random sampling',\n",
    "                                                            1:'popularity sampling method used in word2vec',\n",
    "                                                            2:'popularity sampling method by 'log(count+1)+1e-6',\n",
    "                                                            3:'tencent RALM sampling'}\n",
    "                                                            default to 0'\n",
    "    mode(int,optional):the training mode. '{0:point-wise, 1:pair-wise, 2:list-wise}. default to 0'\n",
    "    neg_ratio(int, optional):negative sample ratio, >=1, defaults to 0.\n",
    "    min_item(int, optional):the min item each user must have. defaults to 0.\n",
    "    \n",
    "    returns:\n",
    "    pd.DataFrame:split train and test data with sequence features\n",
    "    \"\"\"\n",
    "    if item_attribute_cols is None:\n",
    "        item_attribute_cols = []\n",
    "    if mode == 2: #list wise learning\n",
    "        assert neg_ratio > 0, 'neg_ratio must be greater than 0 when list-wise learning'\n",
    "    elif mode == 1:#pair wise learning\n",
    "        neg_ratio = 1\n",
    "    print('preprocess data')\n",
    "    data.sort_values(time_col, inplace=True) #sort by time from old to new\n",
    "    train_set, test_set = [], []\n",
    "    n_cold_user = 0\n",
    "    \n",
    "    items_cnt = Counter(data[item_col].tolist())\n",
    "    item_cnt_order = OrderedDict(sorted((items_cnt.items()), key=lambda x:x[1], reverse=True)) #item_id:item_count\n",
    "    neg_list = negative_sample(item_cnt_order, ratio=data.shape[0]*neg_ratio, method_id=sample_method)\n",
    "    neg_idx = 0\n",
    "    for uid, hist in tqdm.tqdm(data.groupby(user_col), desc='generate sequence features'):\n",
    "        pos_list = hist[item_col].tolist()\n",
    "        if len(pos_list) < min_item: #drop this user when his pos_items \n",
    "            n_cold_user += 1\n",
    "            continue\n",
    "        for i in range(1, len(pos_list)):\n",
    "            hist_item = pos_list[:i]\n",
    "            sample = [uid, pos_list[i], hist_item, len(hist_item)]\n",
    "            if len(item_attribute_cols) > 0:\n",
    "                for attr_col in item_attribute_cols: #the history of item attribute features\n",
    "                    sample.append(hist[attr_col].tolist()[:i])\n",
    "            if i != len(pos_list) - 1:\n",
    "                if mode == 0: #point-wise, the last col is label_col, include label 0 and 1\n",
    "                    last_col = 'label'\n",
    "                    train_set.append(sample + [1])\n",
    "                    for _ in range(neg_ratio):\n",
    "                        sample[1] = neg_list[neg_idx]\n",
    "                        neg_idx += 1\n",
    "                        train_set.append(sample + [0])\n",
    "                elif mode == 1: #pair-wise, the last col is neg_col, include one negative item\n",
    "                    last_col = 'neg_items'\n",
    "                    for _ in range(neg_ratio):\n",
    "                        sample_copy = copy.deepcopy(sample)\n",
    "                        sample_copy.append(neg_list[neg_idx])\n",
    "                        neg_idx += 1\n",
    "                        train_set.append(sample_copy)\n",
    "                elif mode == 2:#list-wise, the last col is neg_col, include neg_ratio negative items\n",
    "                    last_col = 'neg_items'\n",
    "                    sample.append(neg_list[neg_idx:neg_idx+neg_ratio])\n",
    "                    neg_idx += neg_ratio\n",
    "                    train_set.append(sample)\n",
    "                else:\n",
    "                    raise ValueError('mode should in (0,1,2)')\n",
    "            else:\n",
    "                test_set.append(sample + [1]) #Note:if mode=1 or 2, the label col is useless.\n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    print(\"n_train:%d, n_test:%d\" % (len(train_set), len(test_set)))\n",
    "    print(\"%d cold start user droped \" % (n_cold_user))\n",
    "    \n",
    "    attr_hist_col = ['hist_' + col for col in item_attribute_cols]\n",
    "    df_train = pd.DataFrame(train_set, \n",
    "                            columns=[user_col, item_col, 'hist_' + item_col, 'histlen_' + item_col] + attr_hist_col + [last_col])\n",
    "    df_test = pd.DataFrame(test_set,\n",
    "                          columns=[user_col, item_col, 'hist_'+item_col, 'histlen_'+item_col]+attr_hist_col+[last_col])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d7c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):\n",
    "    \"\"\"\n",
    "    pads sequences(list of list) to the ndarray of same length\n",
    "    This is an equivalent implementation of tf.keras.preprocessing.sequence.pad_sequences\n",
    "    \"\"\"\n",
    "    assert padding in ['pre', 'post'], 'Invalid padding={}.'.format(padding)\n",
    "    assert truncating in ['pre', 'post'], 'Invalid truncating={}'.format(truncating)\n",
    "    \n",
    "    if maxlen is None:\n",
    "        maxlen = max(len(x) for x in sequences)\n",
    "    arr = np.full((len(sequences), maxlen), value, dtype=dtype)\n",
    "    for idx, x in enumerate(sequences):\n",
    "        if len(x) == 0:\n",
    "            continue #empty list\n",
    "        if truncating == 'pre':\n",
    "            trunc = x[-maxlen:]\n",
    "        else:\n",
    "            trunc = x[:maxlen]\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        \n",
    "        if padding == 'pre':\n",
    "            arr[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            arr[idx, :len(trunc)] = trunc\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3e739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dict(data):\n",
    "    \"\"\"\n",
    "    convert the dataframe to a dict type input that the network can accept\n",
    "    \"\"\"\n",
    "    data_dict = data.to_dict('list')\n",
    "    for key in data.keys():\n",
    "        data_dict[key] = np.array(data_dict[key])\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e76734ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input(df, user_profile, user_col, item_profile, item_col, seq_max_len, padding='pre', truncating='pre'):\n",
    "    #merge use_profile and item_profile, pad history sequence feature\n",
    "    df = pd.merge(df, user_profile, on=user_col, how='left') #how=left to keep samples order same as the input\n",
    "    df = pd.merge(df, item_profile, on=item_col, how='left')\n",
    "    for col in df.columns.to_list():\n",
    "        if col.startswith('hist_'):\n",
    "            df[col] = pad_sequences(df[col], maxlen=seq_max_len, value=0, padding=padding, truncating=truncating).tolist()\n",
    "    input_dict = df_to_dict(df)\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa40af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movielens_data(data, load_cache=False):\n",
    "    sparse_features = ['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip', 'cate_id']\n",
    "    user_col, item_col, label_col = 'user_id', 'movie_id', 'label'\n",
    "    \n",
    "    feature_max_idx = {}\n",
    "    for feature in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feature] = lbe.fit_transform(data[feature]) + 1\n",
    "        feature_max_idx[feature] = data[feature].max() + 1\n",
    "        if feature == user_col:\n",
    "            #encode user_id:raw_user_id\n",
    "            user_map = {encode_id + 1: raw_id for encode_id, raw_id in enumerate(lbe.classes_)}\n",
    "        if feature == item_col:\n",
    "            #encode item_id:raw_item_id\n",
    "            item_map = {encode_id + 1: raw_id for encode_id, raw_id in enumerate(lbe.classes_)}\n",
    "    np.save('./raw_id_maps.npy', np.array((user_map, item_map), dtype=object))\n",
    "    \n",
    "    user_profile = data[['user_id', 'gender', 'age', 'occupation', 'zip']].drop_duplicates('user_id')\n",
    "    item_profile = data[['movie_id', 'cate_id']].drop_duplicates('movie_id')\n",
    "    \n",
    "    if load_cache: #if you have run this script before and saved the preprocessed data\n",
    "        x_train, y_train, x_test = np.load('./data_cache.npy', allow_pickle=True)\n",
    "    else:\n",
    "        #Note:mode=2 means list-wise negative sample generate, saved in last col 'neg_items'\n",
    "        df_train, df_test = generate_seq_feature_match(data, user_col, item_col, time_col='timestamp',\n",
    "                                                      item_attribute_cols=[], sample_method=1, mode=2,\n",
    "                                                      neg_ratio=3, min_item=0)\n",
    "        \n",
    "        x_train = gen_model_input(df_train, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "        y_train = np.array([0] * df_train.shape[0]) #label=0 means the first pred value is positive sample\n",
    "        x_test = gen_model_input(df_test, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "        np.save('./data_cache.npy', np.array((x_train, y_train, x_test), dtype=object))\n",
    "    \n",
    "    user_cols = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "    \n",
    "    user_features = [SparseFeature(name, vocab_size=feature_max_idx[name], embed_dim=16) for name in user_cols]\n",
    "    user_features += [\n",
    "        SequenceFeature('hist_movie_id', vocab_size=feature_max_idx['movie_id'], embed_dim=16, pooling='mean',\n",
    "                       shared_with='movie_id')\n",
    "    ]\n",
    "    \n",
    "    item_features = [SparseFeature('movie_id', vocab_size=feature_max_idx['movie_id'], embed_dim=16)]\n",
    "    neg_item_feature = [SequenceFeature('neg_items', vocab_size=feature_max_idx['movie_id'], embed_dim=16,\n",
    "                                       pooling='concat', shared_with='movie_id')]\n",
    "    all_item = df_to_dict(item_profile)\n",
    "    test_user = x_test\n",
    "    return user_features, item_features, neg_item_feature, x_train, y_train, all_item, test_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "444a8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f475b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __getitem__(self, index):\n",
    "        return {k:v[index] for k, v in self.x.items()}, self.y[index]\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96dc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "    def __getitem__(self, index):\n",
    "        return {k:v[index] for k, v in self.x.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.x[list(self.x.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "003268ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchDataGenerator(object):\n",
    "    def __init__(self, x, y=[]):\n",
    "        super().__init__()\n",
    "        if len(y) != 0:\n",
    "            self.dataset = TorchDataset(x, y)\n",
    "        else:#for pair-wise model, trained without given label\n",
    "            self.dataset = PredictDataset(x)\n",
    "    def generate_dataloader(self, x_test_user, x_all_item, batch_size, num_workers=0):\n",
    "        train_dataloader = DataLoader(self.dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        test_dataset = PredictDataset(x_test_user)\n",
    "        #shuffle = False to keep same order as ground truth\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        item_dataset = PredictDataset(x_all_item)\n",
    "        item_dataloader = DataLoader(item_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        return train_dataloader, test_dataloader, item_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c534862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConcatPooling(nn.Module):\n",
    "    \"\"\"Keep the origin sequence embedding shape\n",
    "   \n",
    "    Shape:\n",
    "    - Input: `(batch_size, seq_length, embed_dim)`\n",
    "    - Output: `(batch_size, seq_length, embed_dim)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        return x\n",
    "\n",
    "\n",
    "class AveragePooling(nn.Module):\n",
    "    \"\"\"Pooling the sequence embedding matrix by `mean`.\n",
    "    \n",
    "    Shape:\n",
    "        - Input\n",
    "            x: `(batch_size, seq_length, embed_dim)`\n",
    "            mask: `(batch_size, 1, seq_length)`\n",
    "        - Output: `(batch_size, embed_dim)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        if mask == None:\n",
    "            return torch.mean(x, dim=1)\n",
    "        else:\n",
    "            sum_pooling_matrix = torch.bmm(mask, x).squeeze(1)\n",
    "            non_padding_length = mask.sum(dim=-1)\n",
    "            return sum_pooling_matrix / (non_padding_length.float() + 1e-16)\n",
    "\n",
    "\n",
    "class SumPooling(nn.Module):\n",
    "    \"\"\"Pooling the sequence embedding matrix by `sum`.\n",
    "\n",
    "    Shape:\n",
    "        - Input\n",
    "            x: `(batch_size, seq_length, embed_dim)`\n",
    "            mask: `(batch_size, 1, seq_length)`\n",
    "        - Output: `(batch_size, embed_dim)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        if mask == None:\n",
    "            return torch.sum(x, dim=1)\n",
    "        else:\n",
    "            return torch.bmm(mask, x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12293412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.embed_dict = nn.ModuleDict()\n",
    "        self.n_dense = 0\n",
    "        \n",
    "        for fea in features:\n",
    "            if fea.name in self.embed_dict:#exist\n",
    "                continue\n",
    "            if isinstance(fea, SparseFeature) and fea.shared_with == None:\n",
    "                self.embed_dict[fea.name] = fea.get_embedding_layer()\n",
    "            elif isinstance(fea, SequenceFeature) and fea.shared_with == None:\n",
    "                self.embed_dict[fea.name] = fea.get_embedding_layer()\n",
    "            elif isinstance(fea, DenseFeature):\n",
    "                self.n_dense += 1\n",
    "    def forward(self, x, features, squeeze_dim=False):\n",
    "        sparse_emb, dense_values = [], []\n",
    "        sparse_exists, dense_exists = False, False\n",
    "        for fea in features:\n",
    "            if isinstance(fea, SparseFeature):\n",
    "                if fea.shared_with == None:\n",
    "                    sparse_emb.append(self.embed_dict[fea.name](x[fea.name].long()).unsqueeze(1))\n",
    "                else:\n",
    "                    sparse_emb.append(self.embed_dict[fea.shared_with](x[fea.name].long()).unsqueeze(1))\n",
    "            elif isinstance(fea, SequenceFeature):\n",
    "                if fea.pooling == 'sum':\n",
    "                    pooling_layer = SumPooling()\n",
    "                elif fea.pooling == 'mean':\n",
    "                    pooling_layer = AveragePooling()\n",
    "                elif fea.pooling == 'concat':\n",
    "                    pooling_layer = ConcatPooling()\n",
    "                else:\n",
    "                    raise ValueError('Sequence pooling method supports only pooling in %s, got %s.' % \n",
    "                                     (['sum', 'mean'], fea.pooling))\n",
    "                fea_mask = InputMask()(x, fea)\n",
    "                if fea.shared_with == None:\n",
    "                    sparse_emb.append(pooling_layer(self.embed_dict[fea.name](x[fea.name].long()), fea_mask).unsqueeze(1))\n",
    "                else:\n",
    "                    sparse_emb.append(pooling_layer(self.embed_dict[fea.shared_with](x[fea.name].long()), fea_mask).unsqueeze(1))\n",
    "            else:\n",
    "                dense_values.append(x[fea.name].float().unsqueeze(1))\n",
    "        if len(dense_values) > 0:\n",
    "            dense_exists = True\n",
    "            dense_values = torch.cat(dense_values, dim=1)\n",
    "        if len(sparse_emb) > 0:\n",
    "            sparse_exists = True\n",
    "            sparse_emb = torch.cat(sparse_emb, dim=1) #[batch_size, num_features, embed_dim]\n",
    "        if squeeze_dim: #if the emb_dim of sparse_features is different, we must squeeze_dim\n",
    "            if dense_exists and not sparse_exists:#only input dense features\n",
    "                return dense_values\n",
    "            elif not dense_exists and sparse_exists:\n",
    "                return sparse_emb.flatten(start_dim=1) #squeeze dim to :[batch_size, num_features*embed_dim]\n",
    "            elif dense_exists and sparse_exists:\n",
    "                return torch.cat((sparse_emb.flatten(start_dim=1), dense_values), dim=1) #concat dense value with sparse embedding\n",
    "            else:\n",
    "                raise ValueError('The input features can note be empty')\n",
    "        else:\n",
    "            if sparse_exists:\n",
    "                return sparse_emb #[batch_size, num_features, embed_dim]\n",
    "            else:\n",
    "                raise ValueError('If keep the original shape:[batch_size, num_features, embed_dim], expected \\\n",
    "                                 %s in feature list, got %s' % ('sparseFeatures', features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "228d6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_layer(act_name):\n",
    "    if isinstance(act_name, str):\n",
    "        if act_name.lower() == 'sigmoid':\n",
    "            act_layer = nn.Sigmoid()\n",
    "        elif act_name.lower() == 'relu':\n",
    "            act_layer = nn.ReLU(inplace=True)\n",
    "        elif act_name.lower() == 'dice':\n",
    "            act_layer = Dice()\n",
    "        elif act_name.lower() == 'prelu':\n",
    "            act_layer = nn.PReLU()\n",
    "        elif act_name.lower() == 'softmax':\n",
    "            act_layer = nn.Softmax(dim=1)\n",
    "    elif issubclass(act_name, nn.Module):\n",
    "        act_layer = act_name()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return act_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ae6e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_layer=True, dims=None, dropout=0, activation='relu'):\n",
    "        super().__init__()\n",
    "        if dims is None:\n",
    "            dims = []\n",
    "        layers = list()\n",
    "        for i_dim in dims:\n",
    "            layers.append(nn.Linear(input_dim, i_dim))\n",
    "            layers.append(nn.BatchNorm1d(i_dim))\n",
    "            layers.append(activation_layer(activation))\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            input_dim = i_dim\n",
    "        if output_layer:\n",
    "            layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "940d4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNormal(object):\n",
    "    def __init__(self, mean=0.0, std=1.0):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, vocab_size, embed_dim):\n",
    "        embed = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        torch.nn.init.normal_(embed.weight, self.mean, self.std)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3c68e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auto_embedding_dim(num_classes):\n",
    "    return np.floor(6 * np.pow(num_classes, 0.26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "616fc244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceFeature(object):\n",
    "    def __init__(self, name, vocab_size, embed_dim=None, pooling='mean', shared_with=None, padding_idx=None,\n",
    "                initializer=RandomNormal(0, 0.0001)):\n",
    "        self.name = name\n",
    "        self.vocab_size = vocab_size\n",
    "        if embed_dim is None:\n",
    "            self.embed_dim = get_auto_embedding_dim(vocab_size)\n",
    "        else:\n",
    "            self.embed_dim = embed_dim\n",
    "        self.pooling = pooling\n",
    "        self.shared_with = shared_with\n",
    "        self.padding_idx = padding_idx\n",
    "        self.initializer = initializer\n",
    "    def __repr__(self):\n",
    "        return f'<SequenceFeature {self.name} with Embedding shape ({self.vocab_size}, {self.embed_dim})>'\n",
    "    def get_embedding_layer(self):\n",
    "        if not hasattr(self, 'embed'):\n",
    "            self.embed = self.initializer(self.vocab_size, self.embed_dim)\n",
    "        return self.embed\n",
    "\n",
    "class SparseFeature(object):\n",
    "    def __init__(self, name, vocab_size, embed_dim=None, shared_with=None, padding_idx=None, \n",
    "                 initializer=RandomNormal(0, 0.0001)):\n",
    "        self.name = name\n",
    "        self.vocab_size = vocab_size\n",
    "        if embed_dim is None:\n",
    "            self.embed_dim = get_auto_embedding_dim(vocab_size)\n",
    "        else:\n",
    "            self.embed_dim = embed_dim\n",
    "        self.shared_with = shared_with\n",
    "        self.padding_idx = padding_idx\n",
    "        self.initializer = initializer\n",
    "    def __repr__(self):\n",
    "        return f'<SparseFeature {self.name} with Embedding shape ({self.vocab_size}, {self.embed_dim})>'\n",
    "    def get_embedding_layer(self):\n",
    "        if not hasattr(self, 'embed'):\n",
    "            self.embed = self.initializer(self.vocab_size, self.embed_dim)\n",
    "        return self.embed\n",
    "\n",
    "class DenseFeature(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.embed_dim = 1\n",
    "    def __repr__(self):\n",
    "        return f'<DenseFeature {self.name}>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "907c5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputMask(nn.Module):\n",
    "    \"\"\"Return inputs mask from given features\n",
    "\n",
    "    Shape:\n",
    "        - Input: \n",
    "            x (dict): {feature_name: feature_value}, sequence feature value is a 2D tensor with shape:`(batch_size, seq_len)`,\\\n",
    "                      sparse/dense feature value is a 1D tensor with shape `(batch_size)`.\n",
    "            features (list or SparseFeature or SequenceFeature): Note that the elements in features are either all instances of SparseFeature or all instances of SequenceFeature.\n",
    "        - Output: \n",
    "            - if input Sparse: `(batch_size, num_features)`\n",
    "            - if input Sequence: `(batch_size, num_features_seq, seq_length)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, features):\n",
    "        mask = []\n",
    "        if not isinstance(features, list):\n",
    "            features = [features]\n",
    "        for fea in features:\n",
    "            if isinstance(fea, SparseFeature) or isinstance(fea, SequenceFeature):\n",
    "                if fea.padding_idx != None:\n",
    "                    fea_mask = x[fea.name].long() != fea.padding_idx\n",
    "                else:\n",
    "                    fea_mask = x[fea.name].long() != -1\n",
    "                mask.append(fea_mask.unsqueeze(1).float())\n",
    "            else:\n",
    "                raise ValueError(\"Only SparseFeature or SequenceFeature support to get mask.\")\n",
    "        return torch.cat(mask, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "558a8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class YoutubeDNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    user_features(list[feature class]):training by the user tower module\n",
    "    item_features(list[feature class]):training by the embedding table, it's the item id feature\n",
    "    neg_item_feature(list[feature class]):training by the embedding table, it's the negative items id feature\n",
    "    user_params(dict):the params of the user tower module, keys include:{'dims':list, 'activation':str, 'dropout':float, 'output_layer':bool}\n",
    "    temperature(float):temperature factor for similarity score, default to 1.0\n",
    "    \"\"\"\n",
    "    def __init__(self, user_features, item_features, neg_item_feature, user_params, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.user_features = user_features\n",
    "        self.item_features = item_features\n",
    "        self.neg_item_feature = neg_item_feature\n",
    "        self.temperature = temperature\n",
    "        self.user_dims = sum([fea.embed_dim for fea in user_features])\n",
    "        self.embedding = EmbeddingLayer(user_features + item_features)\n",
    "        self.user_mlp = MLP(self.user_dims, output_layer=False, **user_params)\n",
    "        self.mode = None\n",
    "    def forward(self, x):\n",
    "        user_embedding = self.user_tower(x)\n",
    "        item_embedding = self.item_tower(x)\n",
    "        if self.mode == 'user':\n",
    "            return user_embedding\n",
    "        if self.mode == 'item':\n",
    "            return item_embedding\n",
    "        #calculate cosine score\n",
    "        y = torch.mul(user_embedding, item_embedding).sum(dim=2)\n",
    "        y = y / self.temperature\n",
    "        return y\n",
    "    def user_tower(self, x):\n",
    "        if self.mode == 'item':\n",
    "            return None\n",
    "        input_user = self.embedding(x, self.user_features, squeeze_dim=True)\n",
    "        user_embedding = self.user_mlp(input_user).unsqueeze(1) \n",
    "        user_embedding = F.normalize(user_embedding, p=2, dim=2)\n",
    "        if self.mode == 'user':\n",
    "            return user_embedding.squeeze(1)\n",
    "        return user_embedding\n",
    "    def item_tower(self, x):\n",
    "        if self.mode == 'user':\n",
    "            return None\n",
    "        pos_embedding = self.embedding(x, self.item_features, squeeze_dim=False)\n",
    "        pos_embedding = F.normalize(pos_embedding, p=2, dim=2)\n",
    "        if self.mode == 'item':\n",
    "            return pos_embedding.squeeze(1)\n",
    "        neg_embeddings = self.embedding(x, self.neg_item_feature, squeeze_dim=False).squeeze(1)\n",
    "        neg_embeddings = F.normalize(neg_embeddings, p=2, dim=2)\n",
    "        return torch.cat((pos_embedding, neg_embeddings), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "435fb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3072a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper(object):\n",
    "    def __init__(self, patience):\n",
    "        self.patience = patience\n",
    "        self.trial_counter = 0\n",
    "        self.best_auc = 0\n",
    "        self.best_weights = None\n",
    "    def stop_training(self, val_auc, weights):\n",
    "        if val_auc > self.best_auc:\n",
    "            self.best_auc = val_auc\n",
    "            self.trial_counter = 0\n",
    "            self.best_weights = copy.deepcopy(weights)\n",
    "            return False\n",
    "        elif self.trial_counter + 1 < self.patience:\n",
    "            self.trial_counter += 1\n",
    "            return False\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dfa1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchTrainer(object):\n",
    "    \"\"\"A general trainer for Matching/Retrieval\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): any matching model.\n",
    "        mode (int, optional): the training mode, `{0:point-wise, 1:pair-wise, 2:list-wise}`. Defaults to 0.\n",
    "        optimizer_fn (torch.optim): optimizer function of pytorch (default = `torch.optim.Adam`).\n",
    "        optimizer_params (dict): parameters of optimizer_fn.\n",
    "        scheduler_fn (torch.optim.lr_scheduler) : torch scheduling class, eg. `torch.optim.lr_scheduler.StepLR`.\n",
    "        scheduler_params (dict): parameters of optimizer scheduler_fn.\n",
    "        n_epoch (int): epoch number of training.\n",
    "        earlystop_patience (int): how long to wait after last time validation auc improved (default=10).\n",
    "        device (str): `\"cpu\"` or `\"cuda:0\"`\n",
    "        gpus (list): id of multi gpu (default=[]). If the length >=1, then the model will wrapped by nn.DataParallel.\n",
    "        model_path (str): the path you want to save the model (default=\"./\"). Note only save the best weight in the validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        mode=0,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "            optimizer_params=None,\n",
    "        scheduler_fn=None,\n",
    "        scheduler_params=None,\n",
    "        n_epoch=10,\n",
    "        earlystop_patience=10,\n",
    "        device=\"cpu\",\n",
    "            gpus=None,\n",
    "        model_path=\"./\",\n",
    "    ):\n",
    "        self.model = model  # for uniform weights save method in one gpu or multi gpu\n",
    "        if gpus is None:\n",
    "            gpus = []\n",
    "        self.gpus = gpus\n",
    "        if len(gpus) > 1:\n",
    "            print('parallel running on these gpus:', gpus)\n",
    "            self.model = torch.nn.DataParallel(self.model, device_ids=gpus)\n",
    "        self.device = torch.device(device)  #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        if optimizer_params is None:\n",
    "            optimizer_params = {\n",
    "                \"lr\": 1e-3,\n",
    "                \"weight_decay\": 1e-5\n",
    "            }\n",
    "        self.mode = mode\n",
    "        if mode == 0:  #point-wise loss, binary cross_entropy\n",
    "            self.criterion = torch.nn.BCELoss()  #default loss binary cross_entropy\n",
    "        elif mode == 1:  #pair-wise loss\n",
    "            self.criterion = BPRLoss()\n",
    "        elif mode == 2:  #list-wise loss, softmax\n",
    "            self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise ValueError(\"mode only contain value in %s, but got %s\" % ([0, 1, 2], mode))\n",
    "        self.optimizer = optimizer_fn(self.model.parameters(), **optimizer_params)  #default optimizer\n",
    "        self.scheduler = None\n",
    "        if scheduler_fn is not None:\n",
    "            self.scheduler = scheduler_fn(self.optimizer, **scheduler_params)\n",
    "        self.evaluate_fn = roc_auc_score  #default evaluate function\n",
    "        self.n_epoch = n_epoch\n",
    "        self.early_stopper = EarlyStopper(patience=earlystop_patience)\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def train_one_epoch(self, data_loader, log_interval=10):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        tk0 = tqdm.tqdm(data_loader, desc=\"train\", smoothing=0, mininterval=1.0)\n",
    "        for i, (x_dict, y) in enumerate(tk0):\n",
    "            x_dict = {k: v.to(self.device) for k, v in x_dict.items()}  #tensor to GPU\n",
    "            y = y.to(self.device)\n",
    "            if self.mode == 0:\n",
    "                y = y.float()  #torch._C._nn.binary_cross_entropy expected Float\n",
    "            else:\n",
    "                y = y.long()  #\n",
    "            if self.mode == 1:  #pair_wise\n",
    "                pos_score, neg_score = self.model(x_dict)\n",
    "                loss = self.criterion(pos_score, neg_score)\n",
    "            else:\n",
    "                y_pred = self.model(x_dict)\n",
    "                loss = self.criterion(y_pred, y)\n",
    "            # used for debug\n",
    "            # if i == 0:\n",
    "            #     print()\n",
    "            #     if self.mode == 0:\n",
    "            #         print('pred: ', [f'{float(each):5.2g}' for each in y_pred.detach().cpu().tolist()])\n",
    "            #         print('truth:', [f'{float(each):5.2g}' for each in y.detach().cpu().tolist()])\n",
    "            #     elif self.mode == 2:\n",
    "            #         pred = y_pred.detach().cpu().mean(0)\n",
    "            #         pred = torch.softmax(pred, dim=0).tolist()\n",
    "            #         print('pred: ', [f'{float(each):4.2g}' for each in pred])\n",
    "            #     elif self.mode == 1:\n",
    "            #         print('pos:', [f'{float(each):5.2g}' for each in pos_score.detach().cpu().tolist()])\n",
    "            #         print('neg: ', [f'{float(each):5.2g}' for each in neg_score.detach().cpu().tolist()])\n",
    "\n",
    "            self.model.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if (i + 1) % log_interval == 0:\n",
    "                tk0.set_postfix(loss=total_loss / log_interval)\n",
    "                total_loss = 0\n",
    "\n",
    "    def fit(self, train_dataloader, val_dataloader=None):\n",
    "        for epoch_i in range(self.n_epoch):\n",
    "            print('epoch:', epoch_i)\n",
    "            self.train_one_epoch(train_dataloader)\n",
    "            if self.scheduler is not None:\n",
    "                if epoch_i % self.scheduler.step_size == 0:\n",
    "                    print(\"Current lr : {}\".format(self.optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "                self.scheduler.step()  #update lr in epoch level by scheduler\n",
    "\n",
    "            if val_dataloader:\n",
    "                auc = self.evaluate(self.model, val_dataloader)\n",
    "                print('epoch:', epoch_i, 'validation: auc:', auc)\n",
    "                if self.early_stopper.stop_training(auc, self.model.state_dict()):\n",
    "                    print(f'validation: best auc: {self.early_stopper.best_auc}')\n",
    "                    self.model.load_state_dict(self.early_stopper.best_weights)\n",
    "                    break\n",
    "        torch.save(self.model.state_dict(), os.path.join(self.model_path,\n",
    "                                                            \"model.pth\"))  #save best auc model\n",
    "\n",
    "\n",
    "    def evaluate(self, model, data_loader):\n",
    "        model.eval()\n",
    "        targets, predicts = list(), list()\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm.tqdm(data_loader, desc=\"validation\", smoothing=0, mininterval=1.0)\n",
    "            for i, (x_dict, y) in enumerate(tk0):\n",
    "                x_dict = {k: v.to(self.device) for k, v in x_dict.items()}\n",
    "                y = y.to(self.device)\n",
    "                y_pred = model(x_dict)\n",
    "                targets.extend(y.tolist())\n",
    "                predicts.extend(y_pred.tolist())\n",
    "        return self.evaluate_fn(targets, predicts)\n",
    "\n",
    "    def predict(self, model, data_loader):\n",
    "        model.eval()\n",
    "        predicts = list()\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm.tqdm(data_loader, desc=\"predict\", smoothing=0, mininterval=1.0)\n",
    "            for i, (x_dict, y) in enumerate(tk0):\n",
    "                x_dict = {k: v.to(self.device) for k, v in x_dict.items()}\n",
    "                y = y.to(self.device)\n",
    "                y_pred = model(x_dict)\n",
    "                predicts.extend(y_pred.tolist())\n",
    "        return predicts\n",
    "\n",
    "    def inference_embedding(self, model, mode, data_loader, model_path):\n",
    "        #inference\n",
    "        assert mode in [\"user\", \"item\"], \"Invalid mode={}.\".format(mode)\n",
    "        model.mode = mode\n",
    "        model.load_state_dict(torch.load(os.path.join(model_path, \"model.pth\")))\n",
    "        model = model.to(self.device)\n",
    "        model.eval()\n",
    "        predicts = []\n",
    "        with torch.no_grad():\n",
    "            tk0 = tqdm.tqdm(data_loader, desc=\"%s inference\" % (mode), smoothing=0, mininterval=1.0)\n",
    "            for i, x_dict in enumerate(tk0):\n",
    "                x_dict = {k: v.to(self.device) for k, v in x_dict.items()}\n",
    "                y_pred = model(x_dict)\n",
    "                predicts.append(y_pred.data)\n",
    "        return torch.cat(predicts, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9b4a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "generate sequence features:   0%|                                                                | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "generate sequence features: 100%|███████████████████████████████████████████████████████| 2/2 [00:00<00:00, 987.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train:96, n_test:2\n",
      "0 cold start user droped \n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 83.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 43.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 40.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 77.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "train:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 41.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "user inference:   0%|                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "user inference: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.13it/s]\n",
      "\n",
      "\n",
      "\n",
      "item inference:   0%|                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "item inference: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16]) torch.Size([93, 16])\n"
     ]
    }
   ],
   "source": [
    "user_features, item_features, neg_item_feature, x_train, y_train, all_item, test_user = get_movielens_data(data)\n",
    "dg = MatchDataGenerator(x=x_train, y=y_train)\n",
    "\n",
    "model = YoutubeDNN(user_features, item_features, neg_item_feature, user_params={'dims':[128, 64, 16]}, temperature=0.02)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-6\n",
    "epoch = 10\n",
    "device = 'cpu'\n",
    "batch_size = 2048\n",
    "save_dir = './'\n",
    "trainer = MatchTrainer(model, mode=2, optimizer_params={'lr':learning_rate, 'weight_decay':weight_decay},\n",
    "                      n_epoch=epoch, device=device, model_path=save_dir)\n",
    "train_dl, test_dl, item_dl = dg.generate_dataloader(test_user, all_item, batch_size=batch_size)\n",
    "trainer.fit(train_dl)\n",
    "\n",
    "print('inference embedding')\n",
    "user_embedding = trainer.inference_embedding(model=model, mode='user', data_loader=test_dl, model_path=save_dir)\n",
    "item_embedding = trainer.inference_embedding(model=model, mode='item', data_loader=item_dl, model_path=save_dir)\n",
    "\n",
    "print(user_embedding.shape, item_embedding.shape)\n",
    "#torch.save(user_embedding.data.cpu(), save_dir+'user_embedding.pth')\n",
    "#torch.save(item_embedding.data.cpu(), save_dir+'item_embedding.pth')\n",
    "# match_evaluation(user_embedding, item_embedding, test_user, all_item, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81ef7232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoutubeDNN(\n",
       "  (embedding): EmbeddingLayer(\n",
       "    (embed_dict): ModuleDict(\n",
       "      (user_id): Embedding(3, 16)\n",
       "      (gender): Embedding(3, 16)\n",
       "      (age): Embedding(3, 16)\n",
       "      (occupation): Embedding(3, 16)\n",
       "      (zip): Embedding(3, 16)\n",
       "      (movie_id): Embedding(94, 16)\n",
       "    )\n",
       "  )\n",
       "  (user_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=96, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Dropout(p=0, inplace=False)\n",
       "      (8): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU(inplace=True)\n",
       "      (11): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4f808bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, list, dict, numpy.ndarray, dict, dict)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_features), type(item_features), type(neg_item_feature), type(x_train), type(y_train), type(all_item), type(test_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f7bf8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 96, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc6b2963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<SparseFeature user_id with Embedding shape (3, 16)>,\n",
       " <SparseFeature gender with Embedding shape (3, 16)>,\n",
       " <SparseFeature age with Embedding shape (3, 16)>,\n",
       " <SparseFeature occupation with Embedding shape (3, 16)>,\n",
       " <SparseFeature zip with Embedding shape (3, 16)>,\n",
       " <SequenceFeature hist_movie_id with Embedding shape (94, 16)>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bb05f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<SparseFeature movie_id with Embedding shape (94, 16)>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79d3a85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<SequenceFeature neg_items with Embedding shape (94, 16)>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_item_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00815840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_id': array([35, 37, 43, 32, 78, 36, 34, 92,  3, 79, 86, 82, 44, 56, 40, 21, 30,\n",
       "        93, 80, 81, 39, 61, 60, 62, 88, 15, 38, 45, 31, 64, 84, 58, 76, 49,\n",
       "        89, 16, 52, 83,  7, 75, 87, 68, 51, 25, 41, 90, 65,  6, 59, 53,  8,\n",
       "        46, 50, 91, 74,  5, 18, 23, 14, 70, 55, 24, 28, 57,  4, 26, 29, 22,\n",
       "        73, 42, 71, 17, 77, 10, 85, 72, 27, 12, 33, 67, 47,  9, 13,  1, 69,\n",
       "        19, 11, 20, 66, 63, 54, 48,  2]),\n",
       " 'cate_id': array([ 1,  7,  7,  7,  5,  6,  7,  7,  1,  5,  7,  7,  7,  7,  2,  7,  7,\n",
       "         1,  7,  7,  7,  7,  1,  6,  5,  7,  7,  5,  5,  5,  5,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  7,  1,  7,  3,  5,  1,  9,  1,  1,  7,  1,\n",
       "         1,  1,  7,  5,  1,  3,  2,  6,  1,  7,  8,  8,  3,  7,  4,  4,  8,\n",
       "         5,  1, 10,  3,  5,  4,  3,  5,  3,  3,  1,  7,  7,  7,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  2,  3])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99854ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': array([2, 1]),\n",
       " 'movie_id': array([50,  2]),\n",
       " 'hist_movie_id': array([[ 0,  0,  0,  0, 35, 37, 43, 32, 78, 36, 34, 92,  3, 79, 86, 82,\n",
       "         44, 56, 40, 21, 30, 93, 80, 81, 39, 61, 60, 62, 88, 15, 38, 45,\n",
       "         31, 64, 84, 58, 76, 49, 89, 16, 52, 83,  7, 75, 68, 90,  6, 59,\n",
       "          8, 46],\n",
       "        [25, 41, 65, 53, 91, 34, 74, 32,  5, 18, 23, 14, 70, 55, 58, 82,\n",
       "         24, 28, 56, 57,  4, 26, 29, 22, 42, 73, 71, 38, 17, 77, 10, 85,\n",
       "         72, 64, 27, 33, 12, 67, 47,  9, 13,  1, 69, 19, 11, 20, 66, 63,\n",
       "         48, 54]]),\n",
       " 'histlen_movie_id': array([46, 52]),\n",
       " 'neg_items': array([1, 1]),\n",
       " 'gender': array([2, 1]),\n",
       " 'age': array([2, 1]),\n",
       " 'occupation': array([2, 1]),\n",
       " 'zip': array([2, 1]),\n",
       " 'cate_id': array([1, 3])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0edc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
